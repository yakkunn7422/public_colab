{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yakkunn7422/public_colab/blob/main/2024_AIC2_thema1_main5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yV094ubTpxU",
        "outputId": "7088757e-1800-4e8a-ae27-26cad6c6a85a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -fr /content/sample_data/new_train_images\n",
        "!rm -fr /content/sample_data/test_images.zip\n",
        "!rm -fr /content/sample_data/train_images.zip\n",
        "!rm -fr /content/sample_data/train_master.tsv\n",
        "!rm -fr /content/sample_data/sample_submit.tsv\n",
        "!rm -fr /content/sample_data/resnet18-5c106cde.pth\n",
        "!rm -fr /content/sample_data/label_master.tsv\n"
      ],
      "metadata": {
        "id": "eSv5cFmrspCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"カレントワーキングディレクトリは[\" + os.getcwd() + \"]です\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1sc0AqCvqXO",
        "outputId": "a9d2a3e3-089a-4d8d-eff5-03655d36ad0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カレントワーキングディレクトリは[/content]です\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_data 配下にResnet18使う際のデータ一式を持ってくるコード\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "#パラメータ\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "\n",
        "\n",
        "#trainイメージファイル、testイメージファイル等のファイル格納先\n",
        "input_dir = '/content/drive/MyDrive/2024_AIContest2/Thema1'\n",
        "work_dir =  '/content/sample_data'\n",
        "\n",
        "#trainデータの解凍・成形先のディレクトリ\n",
        "output_dir = os.path.join(work_dir, 'new_train_images')\n",
        "\n",
        "#trainデータファイル名\n",
        "zip_file_path = os.path.join(work_dir, 'train_images.zip')\n",
        "#trainデータのラベルまとめファイル名\n",
        "tsv_file_path = os.path.join(work_dir, 'train_master.tsv')\n",
        "\n",
        "# ファイルをCOPYする\n",
        "def simple_copy_files(src_dir, dst_dir):\n",
        "    os.makedirs(dst_dir, exist_ok=True)  # コピー先ディレクトリを作成（既に存在する場合は何もしない）\n",
        "\n",
        "    for file_name in os.listdir(src_dir):\n",
        "        full_file_name = os.path.join(src_dir, file_name)\n",
        "        if os.path.isfile(full_file_name):\n",
        "            shutil.copy2(full_file_name, dst_dir)  # ファイルのコピー\n",
        "\n",
        "# トレインとバリデーション用のディレクトリおよびその中のラベルごとのサブディレクトリを作成する\n",
        "def create_directories(base_dir, labels):\n",
        "\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "    val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "    for dir_path in [train_dir, val_dir]:\n",
        "        if not os.path.exists(dir_path):\n",
        "            os.makedirs(dir_path)\n",
        "\n",
        "    for label in labels:\n",
        "        os.makedirs(os.path.join(train_dir, str(label)), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, str(label)), exist_ok=True)\n",
        "\n",
        "    return train_dir, val_dir\n",
        "\n",
        "# ZIPファイルを解凍する\n",
        "def extract_zip(zip_file_path, extract_to):\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# TSVファイルを読み込み、1行目を削除してデータフレームを準備する\n",
        "def load_and_prepare_data(tsv_file_path):\n",
        "\n",
        "    df = pd.read_csv(tsv_file_path, sep='\\t', names=['filename', 'label_id'])\n",
        "    df = df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 画像ファイルをディレクトリに分配する\n",
        "def distribute_images(df, image_dir, train_dir, val_dir, train_ratio=0.8):\n",
        "\n",
        "    for label in df['label_id'].unique():\n",
        "        label_images = df[df['label_id'] == label]['filename'].tolist()\n",
        "        # シャッフルして分割\n",
        "\n",
        "        np.random.shuffle(label_images)\n",
        "        train_size = int(len(label_images) * train_ratio)\n",
        "        train_images = label_images[:train_size]\n",
        "        val_images = label_images[train_size:]\n",
        "\n",
        "        for image_name in train_images:\n",
        "            src_path = os.path.join(image_dir, image_name)\n",
        "            dst_path = os.path.join(train_dir, str(label), image_name)\n",
        "            shutil.copy(src_path, dst_path)\n",
        "\n",
        "        for image_name in val_images:\n",
        "            src_path = os.path.join(image_dir, image_name)\n",
        "            dst_path = os.path.join(val_dir, str(label), image_name)\n",
        "            shutil.copy(src_path, dst_path)\n",
        "\n",
        "# ディレクトリ内のアイテムを探索し数を表示する\n",
        "def count_files_recursive(directory):\n",
        "    total_files = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        files_count = len(files)\n",
        "        subdir_relative = os.path.relpath(root, directory)\n",
        "        print(f\"Directory '{subdir_relative}' contains {files_count} files.\")\n",
        "\n",
        "        total_files += files_count\n",
        "\n",
        "    print(f\"Total files in '{directory}': {total_files}\")\n",
        "\n",
        "# メイン処理を実行する関数\n",
        "def main(zip_file_path, tsv_file_path, output_dir, train_ratio=0.8):\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    df = load_and_prepare_data(tsv_file_path)\n",
        "\n",
        "    extract_zip(zip_file_path, output_dir)\n",
        "\n",
        "    labels = df['label_id'].unique()\n",
        "\n",
        "    train_dir, val_dir = create_directories(output_dir, labels)\n",
        "    image_dir = os.path.join(output_dir, 'train_images')\n",
        "\n",
        "    distribute_images(df, image_dir, train_dir, val_dir, train_ratio)\n",
        "\n",
        "    # 解凍後のディレクトリを削除\n",
        "    if os.path.exists(image_dir):\n",
        "        shutil.rmtree(image_dir)\n",
        "        print(f\"Deleted temporary directory: {image_dir}\")\n",
        "\n",
        "# 実行\n",
        "# INPUTディレクトリのファイルをOUTPUTディレクトリにすべてCOPY\n",
        "simple_copy_files(input_dir,work_dir)\n",
        "# Train.zipファイル内の画像をtrain、val毎(割合い0.8)かつラベル毎のディレクトリに配置\n",
        "main(zip_file_path, tsv_file_path, output_dir, train_ratio = TRAIN_RATIO)\n",
        "\n",
        "count_files_recursive(output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntYmciZaU67Y",
        "outputId": "845a4bff-de6e-44fc-ff69-8963341c2e9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted temporary directory: /content/sample_data/new_train_images/train_images\n",
            "Directory '.' contains 0 files.\n",
            "Directory 'train' contains 0 files.\n",
            "Directory 'train/8' contains 400 files.\n",
            "Directory 'train/4' contains 400 files.\n",
            "Directory 'train/0' contains 400 files.\n",
            "Directory 'train/5' contains 400 files.\n",
            "Directory 'train/6' contains 400 files.\n",
            "Directory 'train/7' contains 400 files.\n",
            "Directory 'train/1' contains 400 files.\n",
            "Directory 'train/2' contains 400 files.\n",
            "Directory 'train/3' contains 400 files.\n",
            "Directory 'train/9' contains 400 files.\n",
            "Directory 'val' contains 0 files.\n",
            "Directory 'val/8' contains 100 files.\n",
            "Directory 'val/4' contains 100 files.\n",
            "Directory 'val/0' contains 100 files.\n",
            "Directory 'val/5' contains 100 files.\n",
            "Directory 'val/6' contains 100 files.\n",
            "Directory 'val/7' contains 100 files.\n",
            "Directory 'val/1' contains 100 files.\n",
            "Directory 'val/2' contains 100 files.\n",
            "Directory 'val/3' contains 100 files.\n",
            "Directory 'val/9' contains 100 files.\n",
            "Total files in '/content/sample_data/new_train_images': 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet18で学習\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import albumentations\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/2024_AIContest2/Thema1'\n",
        "work_dir =  '/content/sample_data'\n",
        "\n",
        "\n",
        "#定数設定\n",
        "DEVICE= \"cuda\" # cpu or cuda\n",
        "TARGET_NUM = 10\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCH = 40\n",
        "TRANSFER_LEARNING = False\n",
        "MODEL_LEARNING = True\n",
        "\n",
        "#transforms定義\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "#dataset作成\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder('/content/sample_data/new_train_images/train',data_transforms['train']),\n",
        "    'val': datasets.ImageFolder('/content/sample_data/new_train_images/val',data_transforms['val'])\n",
        "}\n",
        "\n",
        "#dataloaders作成\n",
        "image_dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True),\n",
        "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=True),\n",
        "}\n",
        "\n",
        "#dataサイズ定義\n",
        "dataset_sizes= {\n",
        "    'train':len(image_datasets['train']),\n",
        "    'val':len(image_datasets['val'])\n",
        "}\n",
        "\n",
        "if not MODEL_LEARNING:\n",
        "    print(\"処理を停止します。\")\n",
        "    sys.exit()  # プログラムを終了\n",
        "\n",
        "#ResNet18モデル定義\n",
        "def get_model(target_num,isPretrained=False):\n",
        "\n",
        "    if(isPretrained):\n",
        "        model_ft = models.resnet18(pretrained=False)\n",
        "        model_ft.load_state_dict(torch.load(os.path.join(work_dir, 'resnet18-5c106cde.pth'), map_location=lambda storage, loc: storage), strict=True)\n",
        "    else:\n",
        "        model_ft = models.resnet18(pretrained=False)\n",
        "\n",
        "    model_ft.fc = nn.Linear(512, target_num)\n",
        "    model_ft = model_ft.to(DEVICE)\n",
        "    return model_ft\n",
        "\n",
        "#モデルのインスタンス作成 転移学習なし（FALSE）\n",
        "model_ft = get_model(target_num=TARGET_NUM,isPretrained=TRANSFER_LEARNING)\n",
        "\n",
        "#最適化関数定義\n",
        "optimizer = optim.SGD(model_ft.parameters(),lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "#loss関数定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#モデル訓練用関数\n",
        "def train_model(model, criterion, optimizer, num_epochs=5,is_saved = False):\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    train_arr1 = np.zeros(EPOCH)\n",
        "    val_arr1   = np.zeros(EPOCH)\n",
        "\n",
        "    # エポック数だけ下記工程の繰り返し\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            print('{}:フェイズ'.format(phase))\n",
        "\n",
        "            # 訓練フェイズと検証フェイズの切り替え\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # dataloadersからバッチサイズだけデータ取り出し、下記工程（1−5）の繰り返し\n",
        "            for i,(inputs, labels) in enumerate(image_dataloaders[phase]):\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                # 1. optimizerの勾配初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 2.モデルに入力データをinputし、outputを取り出す\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # 3. outputと正解ラベルから、lossを算出\n",
        "                loss = criterion(outputs, labels)\n",
        "                print('   loaders:{}回目'.format(i+1)  ,'   loss:{}'.format(loss))\n",
        "\n",
        "                if phase == 'train':\n",
        "                    # 4. 誤差逆伝播法により勾配の算出\n",
        "                    loss.backward()\n",
        "                    # 5. optimizerのパラメータ更新\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('EPOCH{}回目 {} Loss: {:.4f} Acc: {:.4f}'.format(epoch, phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_arr1[epoch]=epoch_acc\n",
        "            else:\n",
        "                val_arr1[epoch]=epoch_acc\n",
        "\n",
        "            # C. 今までのエポックでの精度よりも高い場合はモデルの保存\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                if(is_saved):\n",
        "                    print('Save File original_model_{}.pth'.format(epoch))\n",
        "                    torch.save(model.state_dict(), '/content/drive/MyDrive/2024_AIContest2/Thema1/pth/original_model_{}.pth'.format(epoch))\n",
        "\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    print(train_arr1)\n",
        "    print(val_arr1)\n",
        "    train_ser1 = pd.Series(train_arr1,name='train_acc')\n",
        "    result_data = pd.DataFrame(train_ser1)\n",
        "    result_data['val_acc']=val_arr1\n",
        "    result_data.plot()\n",
        "    plt.show()\n",
        "\n",
        "train_model(model = model_ft,criterion = criterion,optimizer = optimizer,num_epochs=EPOCH,is_saved = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rT5-iG63rug-",
        "outputId": "d18e58cf-a852-4983-dbfb-76db057dd991"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:フェイズ\n",
            "   loaders:1回目    loss:2.365346908569336\n",
            "   loaders:2回目    loss:2.322838306427002\n",
            "   loaders:3回目    loss:2.331510543823242\n",
            "   loaders:4回目    loss:2.286303758621216\n",
            "   loaders:5回目    loss:2.2926926612854004\n",
            "   loaders:6回目    loss:2.3187785148620605\n",
            "   loaders:7回目    loss:2.2561707496643066\n",
            "   loaders:8回目    loss:2.162461757659912\n",
            "   loaders:9回目    loss:2.1427595615386963\n",
            "   loaders:10回目    loss:2.0776526927948\n",
            "   loaders:11回目    loss:2.072084426879883\n",
            "   loaders:12回目    loss:2.0454494953155518\n",
            "   loaders:13回目    loss:2.0235908031463623\n",
            "   loaders:14回目    loss:1.946914553642273\n",
            "   loaders:15回目    loss:1.98306143283844\n",
            "   loaders:16回目    loss:1.9128220081329346\n",
            "   loaders:17回目    loss:2.0135931968688965\n",
            "   loaders:18回目    loss:1.9095648527145386\n",
            "   loaders:19回目    loss:1.7923955917358398\n",
            "   loaders:20回目    loss:2.01763916015625\n",
            "   loaders:21回目    loss:1.7405920028686523\n",
            "   loaders:22回目    loss:1.776991367340088\n",
            "   loaders:23回目    loss:1.946682333946228\n",
            "   loaders:24回目    loss:1.8868850469589233\n",
            "   loaders:25回目    loss:1.7834733724594116\n",
            "   loaders:26回目    loss:1.8152669668197632\n",
            "   loaders:27回目    loss:1.795687198638916\n",
            "   loaders:28回目    loss:1.811190128326416\n",
            "   loaders:29回目    loss:1.9613869190216064\n",
            "   loaders:30回目    loss:1.8296085596084595\n",
            "   loaders:31回目    loss:1.644758701324463\n",
            "EPOCH0回目 train Loss: 1.9925 Acc: 0.2203\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.868735671043396\n",
            "   loaders:2回目    loss:2.3928580284118652\n",
            "   loaders:3回目    loss:2.7142179012298584\n",
            "   loaders:4回目    loss:4.238083839416504\n",
            "   loaders:5回目    loss:4.660329818725586\n",
            "   loaders:6回目    loss:4.913083553314209\n",
            "   loaders:7回目    loss:2.9895663261413574\n",
            "EPOCH0回目 val Loss: 3.0434 Acc: 0.1970\n",
            "Save File original_model_0.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:1.681614875793457\n",
            "   loaders:2回目    loss:2.007291555404663\n",
            "   loaders:3回目    loss:1.7653924226760864\n",
            "   loaders:4回目    loss:1.635877251625061\n",
            "   loaders:5回目    loss:1.668393850326538\n",
            "   loaders:6回目    loss:1.8729370832443237\n",
            "   loaders:7回目    loss:1.6484875679016113\n",
            "   loaders:8回目    loss:1.7572269439697266\n",
            "   loaders:9回目    loss:1.834466814994812\n",
            "   loaders:10回目    loss:1.6529144048690796\n",
            "   loaders:11回目    loss:1.7229540348052979\n",
            "   loaders:12回目    loss:1.756086826324463\n",
            "   loaders:13回目    loss:1.7074609994888306\n",
            "   loaders:14回目    loss:1.6891378164291382\n",
            "   loaders:15回目    loss:1.78200101852417\n",
            "   loaders:16回目    loss:1.7515687942504883\n",
            "   loaders:17回目    loss:1.774770736694336\n",
            "   loaders:18回目    loss:1.6454509496688843\n",
            "   loaders:19回目    loss:1.58812415599823\n",
            "   loaders:20回目    loss:1.7209107875823975\n",
            "   loaders:21回目    loss:1.6588072776794434\n",
            "   loaders:22回目    loss:1.5327969789505005\n",
            "   loaders:23回目    loss:1.6301666498184204\n",
            "   loaders:24回目    loss:1.7281461954116821\n",
            "   loaders:25回目    loss:1.5987889766693115\n",
            "   loaders:26回目    loss:1.596548318862915\n",
            "   loaders:27回目    loss:1.517920732498169\n",
            "   loaders:28回目    loss:1.5496448278427124\n",
            "   loaders:29回目    loss:1.6831473112106323\n",
            "   loaders:30回目    loss:1.3857378959655762\n",
            "   loaders:31回目    loss:1.6592950820922852\n",
            "EPOCH1回目 train Loss: 1.6705 Acc: 0.3290\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:2.2341654300689697\n",
            "   loaders:2回目    loss:1.4439822435379028\n",
            "   loaders:3回目    loss:1.3351237773895264\n",
            "   loaders:4回目    loss:1.8955790996551514\n",
            "   loaders:5回目    loss:1.7026777267456055\n",
            "   loaders:6回目    loss:1.6196222305297852\n",
            "   loaders:7回目    loss:1.5170153379440308\n",
            "EPOCH1回目 val Loss: 1.5038 Acc: 0.3170\n",
            "Save File original_model_1.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:1.5897613763809204\n",
            "   loaders:2回目    loss:1.4584351778030396\n",
            "   loaders:3回目    loss:1.6243634223937988\n",
            "   loaders:4回目    loss:1.54725980758667\n",
            "   loaders:5回目    loss:1.4881776571273804\n",
            "   loaders:6回目    loss:1.512291431427002\n",
            "   loaders:7回目    loss:1.5220677852630615\n",
            "   loaders:8回目    loss:1.5672138929367065\n",
            "   loaders:9回目    loss:1.5752149820327759\n",
            "   loaders:10回目    loss:1.5009644031524658\n",
            "   loaders:11回目    loss:1.4498043060302734\n",
            "   loaders:12回目    loss:1.4102964401245117\n",
            "   loaders:13回目    loss:1.5102723836898804\n",
            "   loaders:14回目    loss:1.479536533355713\n",
            "   loaders:15回目    loss:1.585923194885254\n",
            "   loaders:16回目    loss:1.5418285131454468\n",
            "   loaders:17回目    loss:1.5359424352645874\n",
            "   loaders:18回目    loss:1.5487439632415771\n",
            "   loaders:19回目    loss:1.5136581659317017\n",
            "   loaders:20回目    loss:1.3984626531600952\n",
            "   loaders:21回目    loss:1.6108368635177612\n",
            "   loaders:22回目    loss:1.5243618488311768\n",
            "   loaders:23回目    loss:1.5978026390075684\n",
            "   loaders:24回目    loss:1.4207549095153809\n",
            "   loaders:25回目    loss:1.6887987852096558\n",
            "   loaders:26回目    loss:1.3558332920074463\n",
            "   loaders:27回目    loss:1.4773056507110596\n",
            "   loaders:28回目    loss:1.6045961380004883\n",
            "   loaders:29回目    loss:1.4729222059249878\n",
            "   loaders:30回目    loss:1.4317619800567627\n",
            "   loaders:31回目    loss:1.6039873361587524\n",
            "EPOCH2回目 train Loss: 1.5088 Acc: 0.3947\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.4994590282440186\n",
            "   loaders:2回目    loss:1.0837188959121704\n",
            "   loaders:3回目    loss:1.2952460050582886\n",
            "   loaders:4回目    loss:1.697475552558899\n",
            "   loaders:5回目    loss:1.9528238773345947\n",
            "   loaders:6回目    loss:1.915763258934021\n",
            "   loaders:7回目    loss:1.5141016244888306\n",
            "EPOCH2回目 val Loss: 1.4027 Acc: 0.3580\n",
            "Save File original_model_2.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:1.3607925176620483\n",
            "   loaders:2回目    loss:1.4746001958847046\n",
            "   loaders:3回目    loss:1.4761197566986084\n",
            "   loaders:4回目    loss:1.389204502105713\n",
            "   loaders:5回目    loss:1.409149169921875\n",
            "   loaders:6回目    loss:1.4753981828689575\n",
            "   loaders:7回目    loss:1.4589146375656128\n",
            "   loaders:8回目    loss:1.4819828271865845\n",
            "   loaders:9回目    loss:1.439415693283081\n",
            "   loaders:10回目    loss:1.3155142068862915\n",
            "   loaders:11回目    loss:1.5692592859268188\n",
            "   loaders:12回目    loss:1.508383870124817\n",
            "   loaders:13回目    loss:1.4187101125717163\n",
            "   loaders:14回目    loss:1.2435344457626343\n",
            "   loaders:15回目    loss:1.3394861221313477\n",
            "   loaders:16回目    loss:1.46665358543396\n",
            "   loaders:17回目    loss:1.4952508211135864\n",
            "   loaders:18回目    loss:1.5386369228363037\n",
            "   loaders:19回目    loss:1.4446214437484741\n",
            "   loaders:20回目    loss:1.3442699909210205\n",
            "   loaders:21回目    loss:1.2823513746261597\n",
            "   loaders:22回目    loss:1.278911828994751\n",
            "   loaders:23回目    loss:1.3838813304901123\n",
            "   loaders:24回目    loss:1.4814236164093018\n",
            "   loaders:25回目    loss:1.4452162981033325\n",
            "   loaders:26回目    loss:1.3500645160675049\n",
            "   loaders:27回目    loss:1.4476919174194336\n",
            "   loaders:28回目    loss:1.6205685138702393\n",
            "   loaders:29回目    loss:1.3440359830856323\n",
            "   loaders:30回目    loss:1.4669462442398071\n",
            "   loaders:31回目    loss:1.4131258726119995\n",
            "EPOCH3回目 train Loss: 1.4133 Acc: 0.4473\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:2.2426917552948\n",
            "   loaders:2回目    loss:1.7726168632507324\n",
            "   loaders:3回目    loss:1.4923464059829712\n",
            "   loaders:4回目    loss:1.7926545143127441\n",
            "   loaders:5回目    loss:1.8955776691436768\n",
            "   loaders:6回目    loss:1.4765716791152954\n",
            "   loaders:7回目    loss:3.2483139038085938\n",
            "EPOCH3回目 val Loss: 1.7819 Acc: 0.3090\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:1.2472425699234009\n",
            "   loaders:2回目    loss:1.235364556312561\n",
            "   loaders:3回目    loss:1.4136614799499512\n",
            "   loaders:4回目    loss:1.2659943103790283\n",
            "   loaders:5回目    loss:1.303398847579956\n",
            "   loaders:6回目    loss:1.342490553855896\n",
            "   loaders:7回目    loss:1.3351625204086304\n",
            "   loaders:8回目    loss:1.2779159545898438\n",
            "   loaders:9回目    loss:1.1861389875411987\n",
            "   loaders:10回目    loss:1.3195849657058716\n",
            "   loaders:11回目    loss:1.4186912775039673\n",
            "   loaders:12回目    loss:1.3021204471588135\n",
            "   loaders:13回目    loss:1.4818700551986694\n",
            "   loaders:14回目    loss:1.233963131904602\n",
            "   loaders:15回目    loss:1.2179663181304932\n",
            "   loaders:16回目    loss:1.3109173774719238\n",
            "   loaders:17回目    loss:1.2061131000518799\n",
            "   loaders:18回目    loss:1.1973423957824707\n",
            "   loaders:19回目    loss:1.3644599914550781\n",
            "   loaders:20回目    loss:1.3680580854415894\n",
            "   loaders:21回目    loss:1.2959821224212646\n",
            "   loaders:22回目    loss:1.381739616394043\n",
            "   loaders:23回目    loss:1.3798116445541382\n",
            "   loaders:24回目    loss:1.4171591997146606\n",
            "   loaders:25回目    loss:1.3582634925842285\n",
            "   loaders:26回目    loss:1.233319878578186\n",
            "   loaders:27回目    loss:1.4158307313919067\n",
            "   loaders:28回目    loss:1.437707543373108\n",
            "   loaders:29回目    loss:1.1921385526657104\n",
            "   loaders:30回目    loss:1.261014461517334\n",
            "   loaders:31回目    loss:1.3677847385406494\n",
            "EPOCH4回目 train Loss: 1.3046 Acc: 0.4970\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:3.176906108856201\n",
            "   loaders:2回目    loss:1.956429123878479\n",
            "   loaders:3回目    loss:1.2644470930099487\n",
            "   loaders:4回目    loss:1.8268097639083862\n",
            "   loaders:5回目    loss:2.307377338409424\n",
            "   loaders:6回目    loss:2.43334698677063\n",
            "   loaders:7回目    loss:0.8439202904701233\n",
            "EPOCH4回目 val Loss: 1.7676 Acc: 0.3280\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:1.2128612995147705\n",
            "   loaders:2回目    loss:1.133397102355957\n",
            "   loaders:3回目    loss:1.1795893907546997\n",
            "   loaders:4回目    loss:1.190211296081543\n",
            "   loaders:5回目    loss:1.0205682516098022\n",
            "   loaders:6回目    loss:1.0898979902267456\n",
            "   loaders:7回目    loss:1.3312608003616333\n",
            "   loaders:8回目    loss:1.2461755275726318\n",
            "   loaders:9回目    loss:1.1740803718566895\n",
            "   loaders:10回目    loss:1.2315045595169067\n",
            "   loaders:11回目    loss:1.2623951435089111\n",
            "   loaders:12回目    loss:1.2806440591812134\n",
            "   loaders:13回目    loss:1.2259103059768677\n",
            "   loaders:14回目    loss:1.2840335369110107\n",
            "   loaders:15回目    loss:1.158615231513977\n",
            "   loaders:16回目    loss:1.2005590200424194\n",
            "   loaders:17回目    loss:1.2923682928085327\n",
            "   loaders:18回目    loss:1.343489408493042\n",
            "   loaders:19回目    loss:1.1234718561172485\n",
            "   loaders:20回目    loss:1.3547775745391846\n",
            "   loaders:21回目    loss:1.2219287157058716\n",
            "   loaders:22回目    loss:1.2481443881988525\n",
            "   loaders:23回目    loss:1.0819157361984253\n",
            "   loaders:24回目    loss:1.0997400283813477\n",
            "   loaders:25回目    loss:1.3303353786468506\n",
            "   loaders:26回目    loss:1.1506458520889282\n",
            "   loaders:27回目    loss:1.1872247457504272\n",
            "   loaders:28回目    loss:1.2306019067764282\n",
            "   loaders:29回目    loss:1.0529133081436157\n",
            "   loaders:30回目    loss:1.2032506465911865\n",
            "   loaders:31回目    loss:1.056325078010559\n",
            "EPOCH5回目 train Loss: 1.1904 Acc: 0.5455\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:2.4496498107910156\n",
            "   loaders:2回目    loss:1.267709493637085\n",
            "   loaders:3回目    loss:1.456178069114685\n",
            "   loaders:4回目    loss:2.301772117614746\n",
            "   loaders:5回目    loss:1.5897130966186523\n",
            "   loaders:6回目    loss:1.5407435894012451\n",
            "   loaders:7回目    loss:2.717252492904663\n",
            "EPOCH5回目 val Loss: 1.7053 Acc: 0.3430\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:1.004181146621704\n",
            "   loaders:2回目    loss:1.1025190353393555\n",
            "   loaders:3回目    loss:1.203934907913208\n",
            "   loaders:4回目    loss:1.0517410039901733\n",
            "   loaders:5回目    loss:1.00054931640625\n",
            "   loaders:6回目    loss:1.0755192041397095\n",
            "   loaders:7回目    loss:1.167763590812683\n",
            "   loaders:8回目    loss:1.1496343612670898\n",
            "   loaders:9回目    loss:0.98744136095047\n",
            "   loaders:10回目    loss:1.014005422592163\n",
            "   loaders:11回目    loss:1.1577509641647339\n",
            "   loaders:12回目    loss:0.999746561050415\n",
            "   loaders:13回目    loss:0.9875692129135132\n",
            "   loaders:14回目    loss:1.012617826461792\n",
            "   loaders:15回目    loss:1.092604637145996\n",
            "   loaders:16回目    loss:1.1972843408584595\n",
            "   loaders:17回目    loss:1.2060728073120117\n",
            "   loaders:18回目    loss:1.1333039999008179\n",
            "   loaders:19回目    loss:1.1413365602493286\n",
            "   loaders:20回目    loss:0.9888008832931519\n",
            "   loaders:21回目    loss:1.1203542947769165\n",
            "   loaders:22回目    loss:0.8806421756744385\n",
            "   loaders:23回目    loss:1.0488803386688232\n",
            "   loaders:24回目    loss:0.9953005313873291\n",
            "   loaders:25回目    loss:1.0717970132827759\n",
            "   loaders:26回目    loss:1.0766675472259521\n",
            "   loaders:27回目    loss:1.0713865756988525\n",
            "   loaders:28回目    loss:1.1407731771469116\n",
            "   loaders:29回目    loss:1.2363775968551636\n",
            "   loaders:30回目    loss:1.1440116167068481\n",
            "   loaders:31回目    loss:1.1178995370864868\n",
            "EPOCH6回目 train Loss: 1.0745 Acc: 0.5963\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.062009572982788\n",
            "   loaders:2回目    loss:1.1332966089248657\n",
            "   loaders:3回目    loss:1.775720238685608\n",
            "   loaders:4回目    loss:1.687232255935669\n",
            "   loaders:5回目    loss:2.0930161476135254\n",
            "   loaders:6回目    loss:1.2671681642532349\n",
            "   loaders:7回目    loss:1.8163609504699707\n",
            "EPOCH6回目 val Loss: 1.3869 Acc: 0.3820\n",
            "Save File original_model_6.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.9353600740432739\n",
            "   loaders:2回目    loss:1.070517659187317\n",
            "   loaders:3回目    loss:0.9203535318374634\n",
            "   loaders:4回目    loss:1.022963523864746\n",
            "   loaders:5回目    loss:0.9045229554176331\n",
            "   loaders:6回目    loss:0.9261288046836853\n",
            "   loaders:7回目    loss:1.0205230712890625\n",
            "   loaders:8回目    loss:1.02035391330719\n",
            "   loaders:9回目    loss:1.0985780954360962\n",
            "   loaders:10回目    loss:1.043778419494629\n",
            "   loaders:11回目    loss:1.0160330533981323\n",
            "   loaders:12回目    loss:0.9236776828765869\n",
            "   loaders:13回目    loss:0.8795385956764221\n",
            "   loaders:14回目    loss:1.1174768209457397\n",
            "   loaders:15回目    loss:0.9312264919281006\n",
            "   loaders:16回目    loss:1.0590839385986328\n",
            "   loaders:17回目    loss:0.913329005241394\n",
            "   loaders:18回目    loss:1.003014326095581\n",
            "   loaders:19回目    loss:0.9521222114562988\n",
            "   loaders:20回目    loss:1.1333714723587036\n",
            "   loaders:21回目    loss:0.987315833568573\n",
            "   loaders:22回目    loss:0.9340651035308838\n",
            "   loaders:23回目    loss:1.0045759677886963\n",
            "   loaders:24回目    loss:0.9410988688468933\n",
            "   loaders:25回目    loss:0.8415215015411377\n",
            "   loaders:26回目    loss:0.9584985375404358\n",
            "   loaders:27回目    loss:1.0103813409805298\n",
            "   loaders:28回目    loss:0.9326959848403931\n",
            "   loaders:29回目    loss:0.9850936532020569\n",
            "   loaders:30回目    loss:1.0399911403656006\n",
            "   loaders:31回目    loss:1.0300935506820679\n",
            "EPOCH7回目 train Loss: 0.9778 Acc: 0.6370\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.6688343286514282\n",
            "   loaders:2回目    loss:1.2285706996917725\n",
            "   loaders:3回目    loss:2.1797120571136475\n",
            "   loaders:4回目    loss:1.892438292503357\n",
            "   loaders:5回目    loss:1.4270449876785278\n",
            "   loaders:6回目    loss:0.6966836452484131\n",
            "   loaders:7回目    loss:2.593209981918335\n",
            "EPOCH7回目 val Loss: 1.4959 Acc: 0.4290\n",
            "Save File original_model_7.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.8676711320877075\n",
            "   loaders:2回目    loss:0.8492913246154785\n",
            "   loaders:3回目    loss:0.9250845313072205\n",
            "   loaders:4回目    loss:0.9042189717292786\n",
            "   loaders:5回目    loss:0.9713336229324341\n",
            "   loaders:6回目    loss:0.8690978288650513\n",
            "   loaders:7回目    loss:0.9675384759902954\n",
            "   loaders:8回目    loss:0.796749472618103\n",
            "   loaders:9回目    loss:0.9907070398330688\n",
            "   loaders:10回目    loss:0.9937011003494263\n",
            "   loaders:11回目    loss:0.8585166335105896\n",
            "   loaders:12回目    loss:0.8889185786247253\n",
            "   loaders:13回目    loss:0.8210862874984741\n",
            "   loaders:14回目    loss:0.9448846578598022\n",
            "   loaders:15回目    loss:0.8538103103637695\n",
            "   loaders:16回目    loss:1.0117636919021606\n",
            "   loaders:17回目    loss:0.8496544361114502\n",
            "   loaders:18回目    loss:0.9242602586746216\n",
            "   loaders:19回目    loss:1.0719239711761475\n",
            "   loaders:20回目    loss:0.8812912702560425\n",
            "   loaders:21回目    loss:0.9138484597206116\n",
            "   loaders:22回目    loss:0.9314033389091492\n",
            "   loaders:23回目    loss:0.8973848819732666\n",
            "   loaders:24回目    loss:0.7620574235916138\n",
            "   loaders:25回目    loss:0.948023796081543\n",
            "   loaders:26回目    loss:0.8806982040405273\n",
            "   loaders:27回目    loss:0.9615964889526367\n",
            "   loaders:28回目    loss:0.934090793132782\n",
            "   loaders:29回目    loss:1.0506362915039062\n",
            "   loaders:30回目    loss:0.9397631883621216\n",
            "   loaders:31回目    loss:0.8864094614982605\n",
            "EPOCH8回目 train Loss: 0.9071 Acc: 0.6600\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:0.8334971070289612\n",
            "   loaders:2回目    loss:1.2801437377929688\n",
            "   loaders:3回目    loss:1.004590630531311\n",
            "   loaders:4回目    loss:1.319433569908142\n",
            "   loaders:5回目    loss:1.5861320495605469\n",
            "   loaders:6回目    loss:1.7756917476654053\n",
            "   loaders:7回目    loss:1.6067851781845093\n",
            "EPOCH8回目 val Loss: 1.2040 Acc: 0.4530\n",
            "Save File original_model_8.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.7885823845863342\n",
            "   loaders:2回目    loss:0.9217939376831055\n",
            "   loaders:3回目    loss:0.7003629803657532\n",
            "   loaders:4回目    loss:0.8976815342903137\n",
            "   loaders:5回目    loss:0.899040937423706\n",
            "   loaders:6回目    loss:0.913127064704895\n",
            "   loaders:7回目    loss:0.6246846914291382\n",
            "   loaders:8回目    loss:0.8195370435714722\n",
            "   loaders:9回目    loss:0.6701719164848328\n",
            "   loaders:10回目    loss:0.7168855667114258\n",
            "   loaders:11回目    loss:0.8977747559547424\n",
            "   loaders:12回目    loss:0.8999361991882324\n",
            "   loaders:13回目    loss:0.8280133605003357\n",
            "   loaders:14回目    loss:0.8046888113021851\n",
            "   loaders:15回目    loss:0.6997278928756714\n",
            "   loaders:16回目    loss:0.8662356734275818\n",
            "   loaders:17回目    loss:0.8222094774246216\n",
            "   loaders:18回目    loss:0.6653476357460022\n",
            "   loaders:19回目    loss:0.8786336183547974\n",
            "   loaders:20回目    loss:0.7930282950401306\n",
            "   loaders:21回目    loss:0.8815165758132935\n",
            "   loaders:22回目    loss:0.9164596796035767\n",
            "   loaders:23回目    loss:0.9940604567527771\n",
            "   loaders:24回目    loss:0.7357814908027649\n",
            "   loaders:25回目    loss:0.8693337440490723\n",
            "   loaders:26回目    loss:0.7916096448898315\n",
            "   loaders:27回目    loss:0.8620803356170654\n",
            "   loaders:28回目    loss:0.9903634786605835\n",
            "   loaders:29回目    loss:0.7495478391647339\n",
            "   loaders:30回目    loss:0.8268910050392151\n",
            "   loaders:31回目    loss:0.9132928848266602\n",
            "EPOCH9回目 train Loss: 0.8204 Acc: 0.6920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.6043699979782104\n",
            "   loaders:2回目    loss:1.477596640586853\n",
            "   loaders:3回目    loss:1.4568723440170288\n",
            "   loaders:4回目    loss:1.5092116594314575\n",
            "   loaders:5回目    loss:1.3883888721466064\n",
            "   loaders:6回目    loss:1.3185279369354248\n",
            "   loaders:7回目    loss:0.6889058947563171\n",
            "EPOCH9回目 val Loss: 1.2088 Acc: 0.4660\n",
            "Save File original_model_9.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.7482304573059082\n",
            "   loaders:2回目    loss:0.7044088840484619\n",
            "   loaders:3回目    loss:0.6458868980407715\n",
            "   loaders:4回目    loss:0.7210436463356018\n",
            "   loaders:5回目    loss:0.7698637843132019\n",
            "   loaders:6回目    loss:0.757461428642273\n",
            "   loaders:7回目    loss:0.6945435404777527\n",
            "   loaders:8回目    loss:0.7114306688308716\n",
            "   loaders:9回目    loss:0.7369272112846375\n",
            "   loaders:10回目    loss:0.7527978420257568\n",
            "   loaders:11回目    loss:0.8089457750320435\n",
            "   loaders:12回目    loss:0.9657600522041321\n",
            "   loaders:13回目    loss:0.6625083684921265\n",
            "   loaders:14回目    loss:0.7725944519042969\n",
            "   loaders:15回目    loss:0.8836246132850647\n",
            "   loaders:16回目    loss:0.8430222272872925\n",
            "   loaders:17回目    loss:0.6216550469398499\n",
            "   loaders:18回目    loss:0.7788112759590149\n",
            "   loaders:19回目    loss:0.9189503192901611\n",
            "   loaders:20回目    loss:0.7841115593910217\n",
            "   loaders:21回目    loss:0.6826393008232117\n",
            "   loaders:22回目    loss:0.7449315786361694\n",
            "   loaders:23回目    loss:0.6822957396507263\n",
            "   loaders:24回目    loss:0.8751779794692993\n",
            "   loaders:25回目    loss:0.678042471408844\n",
            "   loaders:26回目    loss:0.5962428450584412\n",
            "   loaders:27回目    loss:0.7429084181785583\n",
            "   loaders:28回目    loss:0.8470354080200195\n",
            "   loaders:29回目    loss:0.6507128477096558\n",
            "   loaders:30回目    loss:0.7438399791717529\n",
            "   loaders:31回目    loss:0.8382763862609863\n",
            "EPOCH10回目 train Loss: 0.7477 Acc: 0.7213\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:2.0832529067993164\n",
            "   loaders:2回目    loss:2.065781354904175\n",
            "   loaders:3回目    loss:1.539941430091858\n",
            "   loaders:4回目    loss:1.9492440223693848\n",
            "   loaders:5回目    loss:1.1083465814590454\n",
            "   loaders:6回目    loss:1.0709238052368164\n",
            "   loaders:7回目    loss:2.948352098464966\n",
            "EPOCH10回目 val Loss: 1.6340 Acc: 0.4170\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.6640844941139221\n",
            "   loaders:2回目    loss:0.7483556866645813\n",
            "   loaders:3回目    loss:0.6023503541946411\n",
            "   loaders:4回目    loss:0.628003716468811\n",
            "   loaders:5回目    loss:0.7045543789863586\n",
            "   loaders:6回目    loss:0.6767274141311646\n",
            "   loaders:7回目    loss:0.5919650793075562\n",
            "   loaders:8回目    loss:0.5727409720420837\n",
            "   loaders:9回目    loss:0.5646551251411438\n",
            "   loaders:10回目    loss:0.5422390699386597\n",
            "   loaders:11回目    loss:0.7127144932746887\n",
            "   loaders:12回目    loss:0.6522367596626282\n",
            "   loaders:13回目    loss:0.5382407307624817\n",
            "   loaders:14回目    loss:0.5440192222595215\n",
            "   loaders:15回目    loss:0.635908842086792\n",
            "   loaders:16回目    loss:0.681713342666626\n",
            "   loaders:17回目    loss:0.703666627407074\n",
            "   loaders:18回目    loss:0.6640061140060425\n",
            "   loaders:19回目    loss:0.4580380916595459\n",
            "   loaders:20回目    loss:0.6601471304893494\n",
            "   loaders:21回目    loss:0.6849658489227295\n",
            "   loaders:22回目    loss:0.5018044114112854\n",
            "   loaders:23回目    loss:0.6516672372817993\n",
            "   loaders:24回目    loss:0.6482003927230835\n",
            "   loaders:25回目    loss:0.5229870080947876\n",
            "   loaders:26回目    loss:0.7551294565200806\n",
            "   loaders:27回目    loss:0.6766179800033569\n",
            "   loaders:28回目    loss:0.6188081502914429\n",
            "   loaders:29回目    loss:0.6501446962356567\n",
            "   loaders:30回目    loss:0.549382746219635\n",
            "   loaders:31回目    loss:0.6724954843521118\n",
            "EPOCH11回目 train Loss: 0.6233 Acc: 0.7722\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.3360508680343628\n",
            "   loaders:2回目    loss:2.38065242767334\n",
            "   loaders:3回目    loss:1.8529579639434814\n",
            "   loaders:4回目    loss:1.5308036804199219\n",
            "   loaders:5回目    loss:2.7587575912475586\n",
            "   loaders:6回目    loss:2.6194050312042236\n",
            "   loaders:7回目    loss:0.7340579032897949\n",
            "EPOCH11回目 val Loss: 1.6912 Acc: 0.3790\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.6623050570487976\n",
            "   loaders:2回目    loss:0.5696123838424683\n",
            "   loaders:3回目    loss:0.4490258991718292\n",
            "   loaders:4回目    loss:0.5512726306915283\n",
            "   loaders:5回目    loss:0.579883337020874\n",
            "   loaders:6回目    loss:0.48778337240219116\n",
            "   loaders:7回目    loss:0.48330020904541016\n",
            "   loaders:8回目    loss:0.5077966451644897\n",
            "   loaders:9回目    loss:0.5040942430496216\n",
            "   loaders:10回目    loss:0.5459675788879395\n",
            "   loaders:11回目    loss:0.4006601870059967\n",
            "   loaders:12回目    loss:0.4853816032409668\n",
            "   loaders:13回目    loss:0.6160378456115723\n",
            "   loaders:14回目    loss:0.5115278363227844\n",
            "   loaders:15回目    loss:0.5186659693717957\n",
            "   loaders:16回目    loss:0.4746236205101013\n",
            "   loaders:17回目    loss:0.5259150266647339\n",
            "   loaders:18回目    loss:0.572062075138092\n",
            "   loaders:19回目    loss:0.717353105545044\n",
            "   loaders:20回目    loss:0.5058618187904358\n",
            "   loaders:21回目    loss:0.36558854579925537\n",
            "   loaders:22回目    loss:0.544064462184906\n",
            "   loaders:23回目    loss:0.6029049158096313\n",
            "   loaders:24回目    loss:0.651086688041687\n",
            "   loaders:25回目    loss:0.5115305185317993\n",
            "   loaders:26回目    loss:0.6219688057899475\n",
            "   loaders:27回目    loss:0.5744521021842957\n",
            "   loaders:28回目    loss:0.5719718933105469\n",
            "   loaders:29回目    loss:0.768828809261322\n",
            "   loaders:30回目    loss:0.6416573524475098\n",
            "   loaders:31回目    loss:0.6533675789833069\n",
            "EPOCH12回目 train Loss: 0.5496 Acc: 0.8017\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:0.8498229384422302\n",
            "   loaders:2回目    loss:1.3773276805877686\n",
            "   loaders:3回目    loss:2.079993724822998\n",
            "   loaders:4回目    loss:1.8310904502868652\n",
            "   loaders:5回目    loss:1.3539787530899048\n",
            "   loaders:6回目    loss:1.2805296182632446\n",
            "   loaders:7回目    loss:2.023204803466797\n",
            "EPOCH12回目 val Loss: 1.3819 Acc: 0.4810\n",
            "Save File original_model_12.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.4387612044811249\n",
            "   loaders:2回目    loss:0.4887494742870331\n",
            "   loaders:3回目    loss:0.6162882447242737\n",
            "   loaders:4回目    loss:0.4363715648651123\n",
            "   loaders:5回目    loss:0.37976086139678955\n",
            "   loaders:6回目    loss:0.46320295333862305\n",
            "   loaders:7回目    loss:0.6156551241874695\n",
            "   loaders:8回目    loss:0.4423048496246338\n",
            "   loaders:9回目    loss:0.49481573700904846\n",
            "   loaders:10回目    loss:0.5155727863311768\n",
            "   loaders:11回目    loss:0.47905078530311584\n",
            "   loaders:12回目    loss:0.37375158071517944\n",
            "   loaders:13回目    loss:0.5150632858276367\n",
            "   loaders:14回目    loss:0.4381304979324341\n",
            "   loaders:15回目    loss:0.33123499155044556\n",
            "   loaders:16回目    loss:0.45645734667778015\n",
            "   loaders:17回目    loss:0.5373532176017761\n",
            "   loaders:18回目    loss:0.46844255924224854\n",
            "   loaders:19回目    loss:0.4061508774757385\n",
            "   loaders:20回目    loss:0.3222034275531769\n",
            "   loaders:21回目    loss:0.3900349736213684\n",
            "   loaders:22回目    loss:0.409662663936615\n",
            "   loaders:23回目    loss:0.4114183783531189\n",
            "   loaders:24回目    loss:0.4064260721206665\n",
            "   loaders:25回目    loss:0.5454621911048889\n",
            "   loaders:26回目    loss:0.45150771737098694\n",
            "   loaders:27回目    loss:0.4091190695762634\n",
            "   loaders:28回目    loss:0.4524537920951843\n",
            "   loaders:29回目    loss:0.4417405426502228\n",
            "   loaders:30回目    loss:0.5563828945159912\n",
            "   loaders:31回目    loss:0.5434246063232422\n",
            "EPOCH13回目 train Loss: 0.4556 Acc: 0.8377\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.8230167627334595\n",
            "   loaders:2回目    loss:1.0395302772521973\n",
            "   loaders:3回目    loss:1.4117978811264038\n",
            "   loaders:4回目    loss:2.212989568710327\n",
            "   loaders:5回目    loss:2.395397663116455\n",
            "   loaders:6回目    loss:2.0815107822418213\n",
            "   loaders:7回目    loss:0.8328973054885864\n",
            "EPOCH13回目 val Loss: 1.5100 Acc: 0.4300\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.3210621774196625\n",
            "   loaders:2回目    loss:0.4149710536003113\n",
            "   loaders:3回目    loss:0.38128721714019775\n",
            "   loaders:4回目    loss:0.45866045355796814\n",
            "   loaders:5回目    loss:0.43565553426742554\n",
            "   loaders:6回目    loss:0.28178873658180237\n",
            "   loaders:7回目    loss:0.3435167074203491\n",
            "   loaders:8回目    loss:0.3358742594718933\n",
            "   loaders:9回目    loss:0.39731451869010925\n",
            "   loaders:10回目    loss:0.3123113811016083\n",
            "   loaders:11回目    loss:0.38470911979675293\n",
            "   loaders:12回目    loss:0.3170487582683563\n",
            "   loaders:13回目    loss:0.4040313959121704\n",
            "   loaders:14回目    loss:0.2836843729019165\n",
            "   loaders:15回目    loss:0.388325959444046\n",
            "   loaders:16回目    loss:0.3953588008880615\n",
            "   loaders:17回目    loss:0.39213550090789795\n",
            "   loaders:18回目    loss:0.33353865146636963\n",
            "   loaders:19回目    loss:0.3420824408531189\n",
            "   loaders:20回目    loss:0.41648849844932556\n",
            "   loaders:21回目    loss:0.35839036107063293\n",
            "   loaders:22回目    loss:0.3672718405723572\n",
            "   loaders:23回目    loss:0.37890416383743286\n",
            "   loaders:24回目    loss:0.4835546314716339\n",
            "   loaders:25回目    loss:0.46050146222114563\n",
            "   loaders:26回目    loss:0.35992273688316345\n",
            "   loaders:27回目    loss:0.5451176166534424\n",
            "   loaders:28回目    loss:0.4008311629295349\n",
            "   loaders:29回目    loss:0.315949410200119\n",
            "   loaders:30回目    loss:0.365128755569458\n",
            "   loaders:31回目    loss:0.401250958442688\n",
            "EPOCH14回目 train Loss: 0.3769 Acc: 0.8635\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.64055335521698\n",
            "   loaders:2回目    loss:3.921140193939209\n",
            "   loaders:3回目    loss:4.464509963989258\n",
            "   loaders:4回目    loss:2.4496023654937744\n",
            "   loaders:5回目    loss:0.9059563875198364\n",
            "   loaders:6回目    loss:2.3178205490112305\n",
            "   loaders:7回目    loss:3.132211446762085\n",
            "EPOCH14回目 val Loss: 2.4105 Acc: 0.3910\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.40121015906333923\n",
            "   loaders:2回目    loss:0.4024352431297302\n",
            "   loaders:3回目    loss:0.3204972445964813\n",
            "   loaders:4回目    loss:0.288522869348526\n",
            "   loaders:5回目    loss:0.3696845471858978\n",
            "   loaders:6回目    loss:0.42332422733306885\n",
            "   loaders:7回目    loss:0.3053332269191742\n",
            "   loaders:8回目    loss:0.40609291195869446\n",
            "   loaders:9回目    loss:0.23818421363830566\n",
            "   loaders:10回目    loss:0.3376390337944031\n",
            "   loaders:11回目    loss:0.3503758907318115\n",
            "   loaders:12回目    loss:0.3270959258079529\n",
            "   loaders:13回目    loss:0.1960199475288391\n",
            "   loaders:14回目    loss:0.3141555190086365\n",
            "   loaders:15回目    loss:0.24727486073970795\n",
            "   loaders:16回目    loss:0.26726406812667847\n",
            "   loaders:17回目    loss:0.3989710211753845\n",
            "   loaders:18回目    loss:0.29569825530052185\n",
            "   loaders:19回目    loss:0.257393479347229\n",
            "   loaders:20回目    loss:0.23840482532978058\n",
            "   loaders:21回目    loss:0.3895474374294281\n",
            "   loaders:22回目    loss:0.36904460191726685\n",
            "   loaders:23回目    loss:0.4116886556148529\n",
            "   loaders:24回目    loss:0.2919226586818695\n",
            "   loaders:25回目    loss:0.30225303769111633\n",
            "   loaders:26回目    loss:0.26912471652030945\n",
            "   loaders:27回目    loss:0.34456557035446167\n",
            "   loaders:28回目    loss:0.3485466539859772\n",
            "   loaders:29回目    loss:0.2239251583814621\n",
            "   loaders:30回目    loss:0.31559303402900696\n",
            "   loaders:31回目    loss:0.32282570004463196\n",
            "EPOCH15回目 train Loss: 0.3192 Acc: 0.8860\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.5591226816177368\n",
            "   loaders:2回目    loss:1.9113677740097046\n",
            "   loaders:3回目    loss:1.6642931699752808\n",
            "   loaders:4回目    loss:2.538987159729004\n",
            "   loaders:5回目    loss:1.5761480331420898\n",
            "   loaders:6回目    loss:1.3570510149002075\n",
            "   loaders:7回目    loss:2.3637521266937256\n",
            "EPOCH15回目 val Loss: 1.6603 Acc: 0.4650\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.1774587333202362\n",
            "   loaders:2回目    loss:0.3612026572227478\n",
            "   loaders:3回目    loss:0.23869654536247253\n",
            "   loaders:4回目    loss:0.2613265812397003\n",
            "   loaders:5回目    loss:0.324911504983902\n",
            "   loaders:6回目    loss:0.2282746583223343\n",
            "   loaders:7回目    loss:0.2322533279657364\n",
            "   loaders:8回目    loss:0.2500346601009369\n",
            "   loaders:9回目    loss:0.17130471765995026\n",
            "   loaders:10回目    loss:0.2698773145675659\n",
            "   loaders:11回目    loss:0.1980123221874237\n",
            "   loaders:12回目    loss:0.2445840984582901\n",
            "   loaders:13回目    loss:0.16911838948726654\n",
            "   loaders:14回目    loss:0.22361746430397034\n",
            "   loaders:15回目    loss:0.20386749505996704\n",
            "   loaders:16回目    loss:0.2745048999786377\n",
            "   loaders:17回目    loss:0.234568789601326\n",
            "   loaders:18回目    loss:0.25576698780059814\n",
            "   loaders:19回目    loss:0.2903021574020386\n",
            "   loaders:20回目    loss:0.21089725196361542\n",
            "   loaders:21回目    loss:0.19560611248016357\n",
            "   loaders:22回目    loss:0.19461432099342346\n",
            "   loaders:23回目    loss:0.3961949944496155\n",
            "   loaders:24回目    loss:0.20939227938652039\n",
            "   loaders:25回目    loss:0.18142077326774597\n",
            "   loaders:26回目    loss:0.2768285870552063\n",
            "   loaders:27回目    loss:0.2034592479467392\n",
            "   loaders:28回目    loss:0.22648346424102783\n",
            "   loaders:29回目    loss:0.2145967334508896\n",
            "   loaders:30回目    loss:0.34505653381347656\n",
            "   loaders:31回目    loss:0.2261303961277008\n",
            "EPOCH16回目 train Loss: 0.2397 Acc: 0.9200\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.9726297855377197\n",
            "   loaders:2回目    loss:1.1358191967010498\n",
            "   loaders:3回目    loss:0.7036798596382141\n",
            "   loaders:4回目    loss:1.2738773822784424\n",
            "   loaders:5回目    loss:2.9007081985473633\n",
            "   loaders:6回目    loss:3.9014973640441895\n",
            "   loaders:7回目    loss:1.4234179258346558\n",
            "EPOCH16回目 val Loss: 1.7039 Acc: 0.4340\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.20894372463226318\n",
            "   loaders:2回目    loss:0.2434248924255371\n",
            "   loaders:3回目    loss:0.1354762464761734\n",
            "   loaders:4回目    loss:0.19833536446094513\n",
            "   loaders:5回目    loss:0.22920459508895874\n",
            "   loaders:6回目    loss:0.15866392850875854\n",
            "   loaders:7回目    loss:0.20883072912693024\n",
            "   loaders:8回目    loss:0.24199308454990387\n",
            "   loaders:9回目    loss:0.3026041090488434\n",
            "   loaders:10回目    loss:0.24610775709152222\n",
            "   loaders:11回目    loss:0.2880522608757019\n",
            "   loaders:12回目    loss:0.274259090423584\n",
            "   loaders:13回目    loss:0.16848839819431305\n",
            "   loaders:14回目    loss:0.21198031306266785\n",
            "   loaders:15回目    loss:0.22744086384773254\n",
            "   loaders:16回目    loss:0.27269914746284485\n",
            "   loaders:17回目    loss:0.369838684797287\n",
            "   loaders:18回目    loss:0.25473156571388245\n",
            "   loaders:19回目    loss:0.2174016535282135\n",
            "   loaders:20回目    loss:0.2763904333114624\n",
            "   loaders:21回目    loss:0.1948007047176361\n",
            "   loaders:22回目    loss:0.23988890647888184\n",
            "   loaders:23回目    loss:0.21627940237522125\n",
            "   loaders:24回目    loss:0.2656589448451996\n",
            "   loaders:25回目    loss:0.16331569850444794\n",
            "   loaders:26回目    loss:0.24054598808288574\n",
            "   loaders:27回目    loss:0.2552371323108673\n",
            "   loaders:28回目    loss:0.21291080117225647\n",
            "   loaders:29回目    loss:0.21377868950366974\n",
            "   loaders:30回目    loss:0.3290349543094635\n",
            "   loaders:31回目    loss:0.24172525107860565\n",
            "EPOCH17回目 train Loss: 0.2339 Acc: 0.9160\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.3142510652542114\n",
            "   loaders:2回目    loss:0.9853501915931702\n",
            "   loaders:3回目    loss:3.4343209266662598\n",
            "   loaders:4回目    loss:1.7115914821624756\n",
            "   loaders:5回目    loss:1.3601537942886353\n",
            "   loaders:6回目    loss:2.4250006675720215\n",
            "   loaders:7回目    loss:4.838986396789551\n",
            "EPOCH17回目 val Loss: 2.0569 Acc: 0.4270\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.20348301529884338\n",
            "   loaders:2回目    loss:0.15673664212226868\n",
            "   loaders:3回目    loss:0.15022802352905273\n",
            "   loaders:4回目    loss:0.25598207116127014\n",
            "   loaders:5回目    loss:0.2429569512605667\n",
            "   loaders:6回目    loss:0.19586974382400513\n",
            "   loaders:7回目    loss:0.28384098410606384\n",
            "   loaders:8回目    loss:0.16839779913425446\n",
            "   loaders:9回目    loss:0.23578430712223053\n",
            "   loaders:10回目    loss:0.1852574348449707\n",
            "   loaders:11回目    loss:0.26032307744026184\n",
            "   loaders:12回目    loss:0.24940736591815948\n",
            "   loaders:13回目    loss:0.16135258972644806\n",
            "   loaders:14回目    loss:0.1642405390739441\n",
            "   loaders:15回目    loss:0.1777753084897995\n",
            "   loaders:16回目    loss:0.2772369384765625\n",
            "   loaders:17回目    loss:0.23213613033294678\n",
            "   loaders:18回目    loss:0.1797405183315277\n",
            "   loaders:19回目    loss:0.15686674416065216\n",
            "   loaders:20回目    loss:0.18288756906986237\n",
            "   loaders:21回目    loss:0.18449470400810242\n",
            "   loaders:22回目    loss:0.11879231780767441\n",
            "   loaders:23回目    loss:0.15974438190460205\n",
            "   loaders:24回目    loss:0.18616041541099548\n",
            "   loaders:25回目    loss:0.14211413264274597\n",
            "   loaders:26回目    loss:0.1649026721715927\n",
            "   loaders:27回目    loss:0.12462382018566132\n",
            "   loaders:28回目    loss:0.12695056200027466\n",
            "   loaders:29回目    loss:0.16334103047847748\n",
            "   loaders:30回目    loss:0.1803930103778839\n",
            "   loaders:31回目    loss:0.15236862003803253\n",
            "EPOCH18回目 train Loss: 0.1864 Acc: 0.9333\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:3.205632448196411\n",
            "   loaders:2回目    loss:2.1136183738708496\n",
            "   loaders:3回目    loss:1.8106149435043335\n",
            "   loaders:4回目    loss:1.2459499835968018\n",
            "   loaders:5回目    loss:2.3148720264434814\n",
            "   loaders:6回目    loss:2.705080032348633\n",
            "   loaders:7回目    loss:1.0048009157180786\n",
            "EPOCH18回目 val Loss: 1.8433 Acc: 0.4190\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.09564348310232162\n",
            "   loaders:2回目    loss:0.1303400844335556\n",
            "   loaders:3回目    loss:0.10007791966199875\n",
            "   loaders:4回目    loss:0.080283023416996\n",
            "   loaders:5回目    loss:0.11966515332460403\n",
            "   loaders:6回目    loss:0.11407266557216644\n",
            "   loaders:7回目    loss:0.13866400718688965\n",
            "   loaders:8回目    loss:0.06689974665641785\n",
            "   loaders:9回目    loss:0.1618344634771347\n",
            "   loaders:10回目    loss:0.1787942349910736\n",
            "   loaders:11回目    loss:0.18291008472442627\n",
            "   loaders:12回目    loss:0.1356988549232483\n",
            "   loaders:13回目    loss:0.14621298015117645\n",
            "   loaders:14回目    loss:0.09090372920036316\n",
            "   loaders:15回目    loss:0.10227781534194946\n",
            "   loaders:16回目    loss:0.14534428715705872\n",
            "   loaders:17回目    loss:0.15993449091911316\n",
            "   loaders:18回目    loss:0.18948784470558167\n",
            "   loaders:19回目    loss:0.11910800635814667\n",
            "   loaders:20回目    loss:0.0907159149646759\n",
            "   loaders:21回目    loss:0.09531658887863159\n",
            "   loaders:22回目    loss:0.15734101831912994\n",
            "   loaders:23回目    loss:0.15751798450946808\n",
            "   loaders:24回目    loss:0.10847119987010956\n",
            "   loaders:25回目    loss:0.13037770986557007\n",
            "   loaders:26回目    loss:0.1506626158952713\n",
            "   loaders:27回目    loss:0.1640377640724182\n",
            "   loaders:28回目    loss:0.14706644415855408\n",
            "   loaders:29回目    loss:0.08235377818346024\n",
            "   loaders:30回目    loss:0.15297338366508484\n",
            "   loaders:31回目    loss:0.1318211406469345\n",
            "EPOCH19回目 train Loss: 0.1289 Acc: 0.9540\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.0689445734024048\n",
            "   loaders:2回目    loss:1.0903035402297974\n",
            "   loaders:3回目    loss:2.5687365531921387\n",
            "   loaders:4回目    loss:1.7991775274276733\n",
            "   loaders:5回目    loss:1.5548268556594849\n",
            "   loaders:6回目    loss:2.8878588676452637\n",
            "   loaders:7回目    loss:3.2169764041900635\n",
            "EPOCH19回目 val Loss: 1.8159 Acc: 0.4670\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.13090620934963226\n",
            "   loaders:2回目    loss:0.0797715112566948\n",
            "   loaders:3回目    loss:0.10968394577503204\n",
            "   loaders:4回目    loss:0.1728595346212387\n",
            "   loaders:5回目    loss:0.12316446751356125\n",
            "   loaders:6回目    loss:0.0650365799665451\n",
            "   loaders:7回目    loss:0.08668318390846252\n",
            "   loaders:8回目    loss:0.06185929477214813\n",
            "   loaders:9回目    loss:0.0814928412437439\n",
            "   loaders:10回目    loss:0.14058808982372284\n",
            "   loaders:11回目    loss:0.1645725816488266\n",
            "   loaders:12回目    loss:0.11113269627094269\n",
            "   loaders:13回目    loss:0.060280755162239075\n",
            "   loaders:14回目    loss:0.06921268254518509\n",
            "   loaders:15回目    loss:0.10972559452056885\n",
            "   loaders:16回目    loss:0.08543020486831665\n",
            "   loaders:17回目    loss:0.0856103003025055\n",
            "   loaders:18回目    loss:0.07150343805551529\n",
            "   loaders:19回目    loss:0.07138422131538391\n",
            "   loaders:20回目    loss:0.08155500143766403\n",
            "   loaders:21回目    loss:0.07493528723716736\n",
            "   loaders:22回目    loss:0.06821756064891815\n",
            "   loaders:23回目    loss:0.07349133491516113\n",
            "   loaders:24回目    loss:0.08436170220375061\n",
            "   loaders:25回目    loss:0.06566357612609863\n",
            "   loaders:26回目    loss:0.09347284585237503\n",
            "   loaders:27回目    loss:0.08598378300666809\n",
            "   loaders:28回目    loss:0.04918554425239563\n",
            "   loaders:29回目    loss:0.08234630525112152\n",
            "   loaders:30回目    loss:0.07983718067407608\n",
            "   loaders:31回目    loss:0.05071813613176346\n",
            "EPOCH20回目 train Loss: 0.0887 Acc: 0.9693\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.1458488702774048\n",
            "   loaders:2回目    loss:0.9202048182487488\n",
            "   loaders:3回目    loss:1.7260658740997314\n",
            "   loaders:4回目    loss:1.595849633216858\n",
            "   loaders:5回目    loss:1.6828877925872803\n",
            "   loaders:6回目    loss:2.215841293334961\n",
            "   loaders:7回目    loss:2.072570562362671\n",
            "EPOCH20回目 val Loss: 1.4540 Acc: 0.5090\n",
            "Save File original_model_20.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.13420477509498596\n",
            "   loaders:2回目    loss:0.04796788841485977\n",
            "   loaders:3回目    loss:0.05410613864660263\n",
            "   loaders:4回目    loss:0.02524823509156704\n",
            "   loaders:5回目    loss:0.08668198436498642\n",
            "   loaders:6回目    loss:0.028732523322105408\n",
            "   loaders:7回目    loss:0.05745493248105049\n",
            "   loaders:8回目    loss:0.0371580496430397\n",
            "   loaders:9回目    loss:0.056355420500040054\n",
            "   loaders:10回目    loss:0.06651600450277328\n",
            "   loaders:11回目    loss:0.039436280727386475\n",
            "   loaders:12回目    loss:0.06893555074930191\n",
            "   loaders:13回目    loss:0.05438311770558357\n",
            "   loaders:14回目    loss:0.0398852601647377\n",
            "   loaders:15回目    loss:0.03500122204422951\n",
            "   loaders:16回目    loss:0.04045338183641434\n",
            "   loaders:17回目    loss:0.04139780253171921\n",
            "   loaders:18回目    loss:0.057600125670433044\n",
            "   loaders:19回目    loss:0.029947752133011818\n",
            "   loaders:20回目    loss:0.039563462138175964\n",
            "   loaders:21回目    loss:0.06408531963825226\n",
            "   loaders:22回目    loss:0.09864610433578491\n",
            "   loaders:23回目    loss:0.030609777197241783\n",
            "   loaders:24回目    loss:0.07032497227191925\n",
            "   loaders:25回目    loss:0.044004183262586594\n",
            "   loaders:26回目    loss:0.03879370167851448\n",
            "   loaders:27回目    loss:0.03965204954147339\n",
            "   loaders:28回目    loss:0.040869902819395065\n",
            "   loaders:29回目    loss:0.035931218415498734\n",
            "   loaders:30回目    loss:0.026895156130194664\n",
            "   loaders:31回目    loss:0.07820138335227966\n",
            "EPOCH21回目 train Loss: 0.0515 Acc: 0.9810\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.307379961013794\n",
            "   loaders:2回目    loss:1.622574806213379\n",
            "   loaders:3回目    loss:2.4880831241607666\n",
            "   loaders:4回目    loss:1.6107137203216553\n",
            "   loaders:5回目    loss:1.2544240951538086\n",
            "   loaders:6回目    loss:1.7588245868682861\n",
            "   loaders:7回目    loss:1.786346673965454\n",
            "EPOCH21回目 val Loss: 1.5140 Acc: 0.5050\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.03126989305019379\n",
            "   loaders:2回目    loss:0.020154913887381554\n",
            "   loaders:3回目    loss:0.04846327751874924\n",
            "   loaders:4回目    loss:0.028989633545279503\n",
            "   loaders:5回目    loss:0.025236772373318672\n",
            "   loaders:6回目    loss:0.06419345736503601\n",
            "   loaders:7回目    loss:0.03130728378891945\n",
            "   loaders:8回目    loss:0.03784158453345299\n",
            "   loaders:9回目    loss:0.02172851376235485\n",
            "   loaders:10回目    loss:0.03717098385095596\n",
            "   loaders:11回目    loss:0.04749796912074089\n",
            "   loaders:12回目    loss:0.022526144981384277\n",
            "   loaders:13回目    loss:0.020315157249569893\n",
            "   loaders:14回目    loss:0.021469440311193466\n",
            "   loaders:15回目    loss:0.034010179340839386\n",
            "   loaders:16回目    loss:0.02556828036904335\n",
            "   loaders:17回目    loss:0.0547315888106823\n",
            "   loaders:18回目    loss:0.043217968195676804\n",
            "   loaders:19回目    loss:0.03414556011557579\n",
            "   loaders:20回目    loss:0.016989342868328094\n",
            "   loaders:21回目    loss:0.02856161817908287\n",
            "   loaders:22回目    loss:0.03244991973042488\n",
            "   loaders:23回目    loss:0.0471794568002224\n",
            "   loaders:24回目    loss:0.030117390677332878\n",
            "   loaders:25回目    loss:0.024022942408919334\n",
            "   loaders:26回目    loss:0.027034586295485497\n",
            "   loaders:27回目    loss:0.030606860294938087\n",
            "   loaders:28回目    loss:0.03547491133213043\n",
            "   loaders:29回目    loss:0.03104114718735218\n",
            "   loaders:30回目    loss:0.06509676575660706\n",
            "   loaders:31回目    loss:0.03295431658625603\n",
            "EPOCH22回目 train Loss: 0.0336 Acc: 0.9870\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.3981003761291504\n",
            "   loaders:2回目    loss:1.36639404296875\n",
            "   loaders:3回目    loss:1.3041616678237915\n",
            "   loaders:4回目    loss:2.2960164546966553\n",
            "   loaders:5回目    loss:3.4632534980773926\n",
            "   loaders:6回目    loss:1.4355051517486572\n",
            "   loaders:7回目    loss:1.293143391609192\n",
            "EPOCH22回目 val Loss: 1.6072 Acc: 0.5250\n",
            "Save File original_model_22.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.020135270431637764\n",
            "   loaders:2回目    loss:0.029062386602163315\n",
            "   loaders:3回目    loss:0.02033066377043724\n",
            "   loaders:4回目    loss:0.023068293929100037\n",
            "   loaders:5回目    loss:0.015529900789260864\n",
            "   loaders:6回目    loss:0.021493781358003616\n",
            "   loaders:7回目    loss:0.03337353840470314\n",
            "   loaders:8回目    loss:0.02148575894534588\n",
            "   loaders:9回目    loss:0.025772850960493088\n",
            "   loaders:10回目    loss:0.02949073351919651\n",
            "   loaders:11回目    loss:0.026368144899606705\n",
            "   loaders:12回目    loss:0.04002945125102997\n",
            "   loaders:13回目    loss:0.016783960163593292\n",
            "   loaders:14回目    loss:0.010785702615976334\n",
            "   loaders:15回目    loss:0.020030753687024117\n",
            "   loaders:16回目    loss:0.023467428982257843\n",
            "   loaders:17回目    loss:0.016812538728117943\n",
            "   loaders:18回目    loss:0.017831863835453987\n",
            "   loaders:19回目    loss:0.021890776231884956\n",
            "   loaders:20回目    loss:0.032114528119564056\n",
            "   loaders:21回目    loss:0.02859840914607048\n",
            "   loaders:22回目    loss:0.017607364803552628\n",
            "   loaders:23回目    loss:0.015114526264369488\n",
            "   loaders:24回目    loss:0.020548462867736816\n",
            "   loaders:25回目    loss:0.01534334011375904\n",
            "   loaders:26回目    loss:0.024092379957437515\n",
            "   loaders:27回目    loss:0.04593406990170479\n",
            "   loaders:28回目    loss:0.030115142464637756\n",
            "   loaders:29回目    loss:0.011792320758104324\n",
            "   loaders:30回目    loss:0.026134831830859184\n",
            "   loaders:31回目    loss:0.01590193435549736\n",
            "EPOCH23回目 train Loss: 0.0229 Acc: 0.9888\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:0.745036244392395\n",
            "   loaders:2回目    loss:0.9669790267944336\n",
            "   loaders:3回目    loss:2.96958589553833\n",
            "   loaders:4回目    loss:1.8828022480010986\n",
            "   loaders:5回目    loss:2.727008581161499\n",
            "   loaders:6回目    loss:1.5776615142822266\n",
            "   loaders:7回目    loss:1.4379507303237915\n",
            "EPOCH23回目 val Loss: 1.5753 Acc: 0.5290\n",
            "Save File original_model_23.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.02045345865190029\n",
            "   loaders:2回目    loss:0.016307257115840912\n",
            "   loaders:3回目    loss:0.013566960580646992\n",
            "   loaders:4回目    loss:0.019803203642368317\n",
            "   loaders:5回目    loss:0.03205426037311554\n",
            "   loaders:6回目    loss:0.01449614018201828\n",
            "   loaders:7回目    loss:0.033486176282167435\n",
            "   loaders:8回目    loss:0.016611317172646523\n",
            "   loaders:9回目    loss:0.026957115158438683\n",
            "   loaders:10回目    loss:0.013065475039184093\n",
            "   loaders:11回目    loss:0.025544287636876106\n",
            "   loaders:12回目    loss:0.010238786228001118\n",
            "   loaders:13回目    loss:0.014641713351011276\n",
            "   loaders:14回目    loss:0.026444315910339355\n",
            "   loaders:15回目    loss:0.016915401443839073\n",
            "   loaders:16回目    loss:0.00973617285490036\n",
            "   loaders:17回目    loss:0.055341240018606186\n",
            "   loaders:18回目    loss:0.009613956324756145\n",
            "   loaders:19回目    loss:0.017237063497304916\n",
            "   loaders:20回目    loss:0.029921161010861397\n",
            "   loaders:21回目    loss:0.03707325458526611\n",
            "   loaders:22回目    loss:0.013531756587326527\n",
            "   loaders:23回目    loss:0.01686553657054901\n",
            "   loaders:24回目    loss:0.035680707544088364\n",
            "   loaders:25回目    loss:0.012245314195752144\n",
            "   loaders:26回目    loss:0.026844358071684837\n",
            "   loaders:27回目    loss:0.01638348400592804\n",
            "   loaders:28回目    loss:0.00811095256358385\n",
            "   loaders:29回目    loss:0.01626422628760338\n",
            "   loaders:30回目    loss:0.016304487362504005\n",
            "   loaders:31回目    loss:0.02162296138703823\n",
            "EPOCH24回目 train Loss: 0.0206 Acc: 0.9875\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.7296044826507568\n",
            "   loaders:2回目    loss:1.820494294166565\n",
            "   loaders:3回目    loss:2.359426498413086\n",
            "   loaders:4回目    loss:2.264069080352783\n",
            "   loaders:5回目    loss:1.6903685331344604\n",
            "   loaders:6回目    loss:1.3598692417144775\n",
            "   loaders:7回目    loss:1.6058844327926636\n",
            "EPOCH24回目 val Loss: 1.6422 Acc: 0.5130\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.010336912237107754\n",
            "   loaders:2回目    loss:0.02075374498963356\n",
            "   loaders:3回目    loss:0.022877948358654976\n",
            "   loaders:4回目    loss:0.010398652404546738\n",
            "   loaders:5回目    loss:0.006133273709565401\n",
            "   loaders:6回目    loss:0.005931216757744551\n",
            "   loaders:7回目    loss:0.01180011685937643\n",
            "   loaders:8回目    loss:0.007900959812104702\n",
            "   loaders:9回目    loss:0.015584876760840416\n",
            "   loaders:10回目    loss:0.020641010254621506\n",
            "   loaders:11回目    loss:0.015984386205673218\n",
            "   loaders:12回目    loss:0.007481229957193136\n",
            "   loaders:13回目    loss:0.012264644727110863\n",
            "   loaders:14回目    loss:0.00648996839299798\n",
            "   loaders:15回目    loss:0.02789182774722576\n",
            "   loaders:16回目    loss:0.005781419109553099\n",
            "   loaders:17回目    loss:0.01116463914513588\n",
            "   loaders:18回目    loss:0.017027176916599274\n",
            "   loaders:19回目    loss:0.02090064063668251\n",
            "   loaders:20回目    loss:0.022906731814146042\n",
            "   loaders:21回目    loss:0.011765029281377792\n",
            "   loaders:22回目    loss:0.011050705797970295\n",
            "   loaders:23回目    loss:0.016791343688964844\n",
            "   loaders:24回目    loss:0.013788873329758644\n",
            "   loaders:25回目    loss:0.011677642352879047\n",
            "   loaders:26回目    loss:0.014057004824280739\n",
            "   loaders:27回目    loss:0.025469908490777016\n",
            "   loaders:28回目    loss:0.010024365969002247\n",
            "   loaders:29回目    loss:0.034144166857004166\n",
            "   loaders:30回目    loss:0.007173891644924879\n",
            "   loaders:31回目    loss:0.00546009186655283\n",
            "EPOCH25回目 train Loss: 0.0141 Acc: 0.9898\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.144229531288147\n",
            "   loaders:2回目    loss:0.9779735207557678\n",
            "   loaders:3回目    loss:2.4998514652252197\n",
            "   loaders:4回目    loss:1.7849130630493164\n",
            "   loaders:5回目    loss:1.7273813486099243\n",
            "   loaders:6回目    loss:2.0570130348205566\n",
            "   loaders:7回目    loss:1.6428166627883911\n",
            "EPOCH25回目 val Loss: 1.5148 Acc: 0.5410\n",
            "Save File original_model_25.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.010331042110919952\n",
            "   loaders:2回目    loss:0.02080763317644596\n",
            "   loaders:3回目    loss:0.007793929427862167\n",
            "   loaders:4回目    loss:0.007318655028939247\n",
            "   loaders:5回目    loss:0.008471156470477581\n",
            "   loaders:6回目    loss:0.006955753546208143\n",
            "   loaders:7回目    loss:0.006778373382985592\n",
            "   loaders:8回目    loss:0.018880071118474007\n",
            "   loaders:9回目    loss:0.014998105354607105\n",
            "   loaders:10回目    loss:0.015493091195821762\n",
            "   loaders:11回目    loss:0.02806156501173973\n",
            "   loaders:12回目    loss:0.010744194500148296\n",
            "   loaders:13回目    loss:0.012998461723327637\n",
            "   loaders:14回目    loss:0.0192963145673275\n",
            "   loaders:15回目    loss:0.01046231109648943\n",
            "   loaders:16回目    loss:0.014022359624505043\n",
            "   loaders:17回目    loss:0.009236693382263184\n",
            "   loaders:18回目    loss:0.00865753460675478\n",
            "   loaders:19回目    loss:0.006257984787225723\n",
            "   loaders:20回目    loss:0.004701620899140835\n",
            "   loaders:21回目    loss:0.008955833502113819\n",
            "   loaders:22回目    loss:0.012486709281802177\n",
            "   loaders:23回目    loss:0.007766075897961855\n",
            "   loaders:24回目    loss:0.04310707747936249\n",
            "   loaders:25回目    loss:0.009718157351016998\n",
            "   loaders:26回目    loss:0.008424213156104088\n",
            "   loaders:27回目    loss:0.014499908313155174\n",
            "   loaders:28回目    loss:0.008004278875887394\n",
            "   loaders:29回目    loss:0.007352715358138084\n",
            "   loaders:30回目    loss:0.023966003209352493\n",
            "   loaders:31回目    loss:0.009961365722119808\n",
            "EPOCH26回目 train Loss: 0.0127 Acc: 0.9908\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.8072023391723633\n",
            "   loaders:2回目    loss:1.5605194568634033\n",
            "   loaders:3回目    loss:2.822432041168213\n",
            "   loaders:4回目    loss:2.795854091644287\n",
            "   loaders:5回目    loss:1.119173288345337\n",
            "   loaders:6回目    loss:1.8084375858306885\n",
            "   loaders:7回目    loss:1.3646479845046997\n",
            "EPOCH26回目 val Loss: 1.6996 Acc: 0.5240\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0051143658347427845\n",
            "   loaders:2回目    loss:0.009663562290370464\n",
            "   loaders:3回目    loss:0.005843487102538347\n",
            "   loaders:4回目    loss:0.008727450855076313\n",
            "   loaders:5回目    loss:0.003631673054769635\n",
            "   loaders:6回目    loss:0.02776334248483181\n",
            "   loaders:7回目    loss:0.006177903618663549\n",
            "   loaders:8回目    loss:0.013144534081220627\n",
            "   loaders:9回目    loss:0.003871830878779292\n",
            "   loaders:10回目    loss:0.010369563475251198\n",
            "   loaders:11回目    loss:0.0073744142428040504\n",
            "   loaders:12回目    loss:0.005561360158026218\n",
            "   loaders:13回目    loss:0.0044400617480278015\n",
            "   loaders:14回目    loss:0.007940717972815037\n",
            "   loaders:15回目    loss:0.0051764072850346565\n",
            "   loaders:16回目    loss:0.008558744564652443\n",
            "   loaders:17回目    loss:0.016639575362205505\n",
            "   loaders:18回目    loss:0.010890448465943336\n",
            "   loaders:19回目    loss:0.011313697323203087\n",
            "   loaders:20回目    loss:0.004927855916321278\n",
            "   loaders:21回目    loss:0.010108502581715584\n",
            "   loaders:22回目    loss:0.006286645773798227\n",
            "   loaders:23回目    loss:0.00711130490526557\n",
            "   loaders:24回目    loss:0.008175031282007694\n",
            "   loaders:25回目    loss:0.007485649548470974\n",
            "   loaders:26回目    loss:0.015327648259699345\n",
            "   loaders:27回目    loss:0.00611500721424818\n",
            "   loaders:28回目    loss:0.00862126424908638\n",
            "   loaders:29回目    loss:0.005685617681592703\n",
            "   loaders:30回目    loss:0.0039617582224309444\n",
            "   loaders:31回目    loss:0.010086068883538246\n",
            "EPOCH27回目 train Loss: 0.0085 Acc: 0.9913\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.2904704809188843\n",
            "   loaders:2回目    loss:1.483984351158142\n",
            "   loaders:3回目    loss:2.1528356075286865\n",
            "   loaders:4回目    loss:1.7586241960525513\n",
            "   loaders:5回目    loss:1.9949133396148682\n",
            "   loaders:6回目    loss:1.5190365314483643\n",
            "   loaders:7回目    loss:1.3911662101745605\n",
            "EPOCH27回目 val Loss: 1.4837 Acc: 0.5350\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.003138170577585697\n",
            "   loaders:2回目    loss:0.004254572093486786\n",
            "   loaders:3回目    loss:0.005724597256630659\n",
            "   loaders:4回目    loss:0.003234154311940074\n",
            "   loaders:5回目    loss:0.00841046404093504\n",
            "   loaders:6回目    loss:0.004807967226952314\n",
            "   loaders:7回目    loss:0.0039743962697684765\n",
            "   loaders:8回目    loss:0.0077573382295668125\n",
            "   loaders:9回目    loss:0.00449588755145669\n",
            "   loaders:10回目    loss:0.0034441177267581224\n",
            "   loaders:11回目    loss:0.00313947512768209\n",
            "   loaders:12回目    loss:0.004510731901973486\n",
            "   loaders:13回目    loss:0.0033932204823940992\n",
            "   loaders:14回目    loss:0.005311328452080488\n",
            "   loaders:15回目    loss:0.006082154344767332\n",
            "   loaders:16回目    loss:0.004762748256325722\n",
            "   loaders:17回目    loss:0.0029809463303536177\n",
            "   loaders:18回目    loss:0.0034207766875624657\n",
            "   loaders:19回目    loss:0.004037895705550909\n",
            "   loaders:20回目    loss:0.003784103551879525\n",
            "   loaders:21回目    loss:0.0024424914736300707\n",
            "   loaders:22回目    loss:0.0014400467043742537\n",
            "   loaders:23回目    loss:0.0038809292018413544\n",
            "   loaders:24回目    loss:0.004602794535458088\n",
            "   loaders:25回目    loss:0.00313826696947217\n",
            "   loaders:26回目    loss:0.004862472880631685\n",
            "   loaders:27回目    loss:0.0025370551738888025\n",
            "   loaders:28回目    loss:0.002514844061806798\n",
            "   loaders:29回目    loss:0.00659744581207633\n",
            "   loaders:30回目    loss:0.004594238009303808\n",
            "   loaders:31回目    loss:0.0037276928778737783\n",
            "EPOCH28回目 train Loss: 0.0042 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.1265034675598145\n",
            "   loaders:2回目    loss:1.1933262348175049\n",
            "   loaders:3回目    loss:2.1461706161499023\n",
            "   loaders:4回目    loss:1.5691083669662476\n",
            "   loaders:5回目    loss:1.8778750896453857\n",
            "   loaders:6回目    loss:1.9364906549453735\n",
            "   loaders:7回目    loss:1.3086388111114502\n",
            "EPOCH28回目 val Loss: 1.4282 Acc: 0.5510\n",
            "Save File original_model_28.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.001953406725078821\n",
            "   loaders:2回目    loss:0.002087657107040286\n",
            "   loaders:3回目    loss:0.002300390973687172\n",
            "   loaders:4回目    loss:0.0036056549288332462\n",
            "   loaders:5回目    loss:0.002374497940763831\n",
            "   loaders:6回目    loss:0.0021081557497382164\n",
            "   loaders:7回目    loss:0.0024159657768905163\n",
            "   loaders:8回目    loss:0.002016367157921195\n",
            "   loaders:9回目    loss:0.0029863412491977215\n",
            "   loaders:10回目    loss:0.002043226733803749\n",
            "   loaders:11回目    loss:0.0013963916571810842\n",
            "   loaders:12回目    loss:0.002281852997839451\n",
            "   loaders:13回目    loss:0.00288082635961473\n",
            "   loaders:14回目    loss:0.0031704993452876806\n",
            "   loaders:15回目    loss:0.0022519160993397236\n",
            "   loaders:16回目    loss:0.0030703379306942225\n",
            "   loaders:17回目    loss:0.002773954765871167\n",
            "   loaders:18回目    loss:0.0022354773245751858\n",
            "   loaders:19回目    loss:0.004632637836039066\n",
            "   loaders:20回目    loss:0.0018009307095780969\n",
            "   loaders:21回目    loss:0.003686359152197838\n",
            "   loaders:22回目    loss:0.0038124003913253546\n",
            "   loaders:23回目    loss:0.0020710204262286425\n",
            "   loaders:24回目    loss:0.0032933345064520836\n",
            "   loaders:25回目    loss:0.0020846170373260975\n",
            "   loaders:26回目    loss:0.0023616808466613293\n",
            "   loaders:27回目    loss:0.0032024767715483904\n",
            "   loaders:28回目    loss:0.0027768558356910944\n",
            "   loaders:29回目    loss:0.001321895164437592\n",
            "   loaders:30回目    loss:0.00300961104221642\n",
            "   loaders:31回目    loss:0.00158155825920403\n",
            "EPOCH29回目 train Loss: 0.0025 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.2845218181610107\n",
            "   loaders:2回目    loss:1.3501386642456055\n",
            "   loaders:3回目    loss:2.1059746742248535\n",
            "   loaders:4回目    loss:1.6716711521148682\n",
            "   loaders:5回目    loss:1.639172077178955\n",
            "   loaders:6回目    loss:1.611527681350708\n",
            "   loaders:7回目    loss:1.4228546619415283\n",
            "EPOCH29回目 val Loss: 1.4190 Acc: 0.5480\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0025735676754266024\n",
            "   loaders:2回目    loss:0.001458404352888465\n",
            "   loaders:3回目    loss:0.0015903860330581665\n",
            "   loaders:4回目    loss:0.0077816518023610115\n",
            "   loaders:5回目    loss:0.0013169057201594114\n",
            "   loaders:6回目    loss:0.0021047918125987053\n",
            "   loaders:7回目    loss:0.0012736074859276414\n",
            "   loaders:8回目    loss:0.0015388954197987914\n",
            "   loaders:9回目    loss:0.0016350134974345565\n",
            "   loaders:10回目    loss:0.002316102385520935\n",
            "   loaders:11回目    loss:0.0013391684042289853\n",
            "   loaders:12回目    loss:0.0021373205818235874\n",
            "   loaders:13回目    loss:0.0019840034656226635\n",
            "   loaders:14回目    loss:0.0025921466294676065\n",
            "   loaders:15回目    loss:0.0017756313318386674\n",
            "   loaders:16回目    loss:0.0034813489764928818\n",
            "   loaders:17回目    loss:0.0024380504619330168\n",
            "   loaders:18回目    loss:0.00217931205406785\n",
            "   loaders:19回目    loss:0.002871158067137003\n",
            "   loaders:20回目    loss:0.002067397814244032\n",
            "   loaders:21回目    loss:0.0016997180646285415\n",
            "   loaders:22回目    loss:0.002661801176145673\n",
            "   loaders:23回目    loss:0.0011366918915882707\n",
            "   loaders:24回目    loss:0.0015558411832898855\n",
            "   loaders:25回目    loss:0.0011895315255969763\n",
            "   loaders:26回目    loss:0.0024088865611702204\n",
            "   loaders:27回目    loss:0.0022551193833351135\n",
            "   loaders:28回目    loss:0.004596796818077564\n",
            "   loaders:29回目    loss:0.00158002192620188\n",
            "   loaders:30回目    loss:0.0014842028031125665\n",
            "   loaders:31回目    loss:0.0018512457609176636\n",
            "EPOCH30回目 train Loss: 0.0022 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.4047133922576904\n",
            "   loaders:2回目    loss:1.436509132385254\n",
            "   loaders:3回目    loss:2.2791218757629395\n",
            "   loaders:4回目    loss:1.7464687824249268\n",
            "   loaders:5回目    loss:1.4845316410064697\n",
            "   loaders:6回目    loss:1.4277340173721313\n",
            "   loaders:7回目    loss:1.395308017730713\n",
            "EPOCH30回目 val Loss: 1.4303 Acc: 0.5520\n",
            "Save File original_model_30.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0018883292796090245\n",
            "   loaders:2回目    loss:0.0014970528427511454\n",
            "   loaders:3回目    loss:0.0018151038093492389\n",
            "   loaders:4回目    loss:0.004020641092211008\n",
            "   loaders:5回目    loss:0.0012829066254198551\n",
            "   loaders:6回目    loss:0.00318466080352664\n",
            "   loaders:7回目    loss:0.0010719356359913945\n",
            "   loaders:8回目    loss:0.002132260473445058\n",
            "   loaders:9回目    loss:0.001552410190925002\n",
            "   loaders:10回目    loss:0.0025768729392439127\n",
            "   loaders:11回目    loss:0.0009807428577914834\n",
            "   loaders:12回目    loss:0.0028921940829604864\n",
            "   loaders:13回目    loss:0.0014147585025057197\n",
            "   loaders:14回目    loss:0.0018251275178045034\n",
            "   loaders:15回目    loss:0.002512747887521982\n",
            "   loaders:16回目    loss:0.0013436005683615804\n",
            "   loaders:17回目    loss:0.0010318388231098652\n",
            "   loaders:18回目    loss:0.0019162092357873917\n",
            "   loaders:19回目    loss:0.001106048235669732\n",
            "   loaders:20回目    loss:0.0018495675176382065\n",
            "   loaders:21回目    loss:0.0036144296173006296\n",
            "   loaders:22回目    loss:0.001847267965786159\n",
            "   loaders:23回目    loss:0.0016182423569262028\n",
            "   loaders:24回目    loss:0.0024799415841698647\n",
            "   loaders:25回目    loss:0.0011781356297433376\n",
            "   loaders:26回目    loss:0.001720266416668892\n",
            "   loaders:27回目    loss:0.0031441333703696728\n",
            "   loaders:28回目    loss:0.0011654807021841407\n",
            "   loaders:29回目    loss:0.002971725771203637\n",
            "   loaders:30回目    loss:0.0016127197304740548\n",
            "   loaders:31回目    loss:0.0018792635528370738\n",
            "EPOCH31回目 train Loss: 0.0020 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.222303032875061\n",
            "   loaders:2回目    loss:1.2152011394500732\n",
            "   loaders:3回目    loss:2.1605987548828125\n",
            "   loaders:4回目    loss:1.777015209197998\n",
            "   loaders:5回目    loss:1.74212646484375\n",
            "   loaders:6回目    loss:1.4975640773773193\n",
            "   loaders:7回目    loss:1.35017728805542\n",
            "EPOCH31回目 val Loss: 1.4035 Acc: 0.5490\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.002273536752909422\n",
            "   loaders:2回目    loss:0.0020970627665519714\n",
            "   loaders:3回目    loss:0.0015065167099237442\n",
            "   loaders:4回目    loss:0.0017884314293041825\n",
            "   loaders:5回目    loss:0.0017648356733843684\n",
            "   loaders:6回目    loss:0.0021613689605146646\n",
            "   loaders:7回目    loss:0.0011000733356922865\n",
            "   loaders:8回目    loss:0.00213155266828835\n",
            "   loaders:9回目    loss:0.0024192151613533497\n",
            "   loaders:10回目    loss:0.0017327343812212348\n",
            "   loaders:11回目    loss:0.0014377415645867586\n",
            "   loaders:12回目    loss:0.002229394856840372\n",
            "   loaders:13回目    loss:0.0018393377540633082\n",
            "   loaders:14回目    loss:0.001427621697075665\n",
            "   loaders:15回目    loss:0.001225633779540658\n",
            "   loaders:16回目    loss:0.001643749768845737\n",
            "   loaders:17回目    loss:0.0019119896460324526\n",
            "   loaders:18回目    loss:0.0014957378152757883\n",
            "   loaders:19回目    loss:0.002087469445541501\n",
            "   loaders:20回目    loss:0.0009603264043107629\n",
            "   loaders:21回目    loss:0.0013059108750894666\n",
            "   loaders:22回目    loss:0.0020610825158655643\n",
            "   loaders:23回目    loss:0.0019243352580815554\n",
            "   loaders:24回目    loss:0.0014235725393518806\n",
            "   loaders:25回目    loss:0.0023036946076899767\n",
            "   loaders:26回目    loss:0.0024882659781724215\n",
            "   loaders:27回目    loss:0.0016498101176694036\n",
            "   loaders:28回目    loss:0.0012699561193585396\n",
            "   loaders:29回目    loss:0.0017690605018287897\n",
            "   loaders:30回目    loss:0.001165791880339384\n",
            "   loaders:31回目    loss:0.0017914745258167386\n",
            "EPOCH32回目 train Loss: 0.0017 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.1782128810882568\n",
            "   loaders:2回目    loss:1.168934941291809\n",
            "   loaders:3回目    loss:2.3224892616271973\n",
            "   loaders:4回目    loss:1.8053168058395386\n",
            "   loaders:5回目    loss:1.6558524370193481\n",
            "   loaders:6回目    loss:1.461557149887085\n",
            "   loaders:7回目    loss:1.4282424449920654\n",
            "EPOCH32回目 val Loss: 1.4106 Acc: 0.5580\n",
            "Save File original_model_32.pth\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0012411067727953196\n",
            "   loaders:2回目    loss:0.0009866312611848116\n",
            "   loaders:3回目    loss:0.0010099142091348767\n",
            "   loaders:4回目    loss:0.001931884791702032\n",
            "   loaders:5回目    loss:0.0009713099570944905\n",
            "   loaders:6回目    loss:0.0012776993680745363\n",
            "   loaders:7回目    loss:0.0011840007500723004\n",
            "   loaders:8回目    loss:0.0015629318077117205\n",
            "   loaders:9回目    loss:0.0017859818181023002\n",
            "   loaders:10回目    loss:0.000989039777778089\n",
            "   loaders:11回目    loss:0.002191983861848712\n",
            "   loaders:12回目    loss:0.0011741520138457417\n",
            "   loaders:13回目    loss:0.0012631257995963097\n",
            "   loaders:14回目    loss:0.001089027151465416\n",
            "   loaders:15回目    loss:0.0016886391676962376\n",
            "   loaders:16回目    loss:0.0019035415025427938\n",
            "   loaders:17回目    loss:0.0018479323480278254\n",
            "   loaders:18回目    loss:0.0013976981863379478\n",
            "   loaders:19回目    loss:0.0012681159423664212\n",
            "   loaders:20回目    loss:0.0012698915088549256\n",
            "   loaders:21回目    loss:0.001159446663223207\n",
            "   loaders:22回目    loss:0.001314259017817676\n",
            "   loaders:23回目    loss:0.0018180225742980838\n",
            "   loaders:24回目    loss:0.0011948395986109972\n",
            "   loaders:25回目    loss:0.001449130242690444\n",
            "   loaders:26回目    loss:0.0008386021945625544\n",
            "   loaders:27回目    loss:0.0011174804531037807\n",
            "   loaders:28回目    loss:0.0012628354597836733\n",
            "   loaders:29回目    loss:0.0012851869687438011\n",
            "   loaders:30回目    loss:0.0012868742924183607\n",
            "   loaders:31回目    loss:0.0011095493100583553\n",
            "EPOCH33回目 train Loss: 0.0013 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.264749526977539\n",
            "   loaders:2回目    loss:1.3395227193832397\n",
            "   loaders:3回目    loss:2.1615915298461914\n",
            "   loaders:4回目    loss:1.7417314052581787\n",
            "   loaders:5回目    loss:1.5945161581039429\n",
            "   loaders:6回目    loss:1.5776727199554443\n",
            "   loaders:7回目    loss:1.4470165967941284\n",
            "EPOCH33回目 val Loss: 1.4242 Acc: 0.5470\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0015452986117452383\n",
            "   loaders:2回目    loss:0.0010881525231525302\n",
            "   loaders:3回目    loss:0.0014495595823973417\n",
            "   loaders:4回目    loss:0.0009872445371001959\n",
            "   loaders:5回目    loss:0.0008579400018788874\n",
            "   loaders:6回目    loss:0.0015253002056851983\n",
            "   loaders:7回目    loss:0.0013529803836718202\n",
            "   loaders:8回目    loss:0.0012881300644949079\n",
            "   loaders:9回目    loss:0.002251397119835019\n",
            "   loaders:10回目    loss:0.0014479324454441667\n",
            "   loaders:11回目    loss:0.0011699802707880735\n",
            "   loaders:12回目    loss:0.0009856827091425657\n",
            "   loaders:13回目    loss:0.0010157109936699271\n",
            "   loaders:14回目    loss:0.0007966448902152479\n",
            "   loaders:15回目    loss:0.0023601646535098553\n",
            "   loaders:16回目    loss:0.0009702934185042977\n",
            "   loaders:17回目    loss:0.0009111301624216139\n",
            "   loaders:18回目    loss:0.0012952180113643408\n",
            "   loaders:19回目    loss:0.0013268737820908427\n",
            "   loaders:20回目    loss:0.0010855065193027258\n",
            "   loaders:21回目    loss:0.0016272616339847445\n",
            "   loaders:22回目    loss:0.0010741385631263256\n",
            "   loaders:23回目    loss:0.0015233518788591027\n",
            "   loaders:24回目    loss:0.0012356563238427043\n",
            "   loaders:25回目    loss:0.0008379301289096475\n",
            "   loaders:26回目    loss:0.001674588187597692\n",
            "   loaders:27回目    loss:0.0010184101993218064\n",
            "   loaders:28回目    loss:0.0018006216268986464\n",
            "   loaders:29回目    loss:0.0011463937116786838\n",
            "   loaders:30回目    loss:0.0007568367873318493\n",
            "   loaders:31回目    loss:0.003684856928884983\n",
            "EPOCH34回目 train Loss: 0.0013 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.2435189485549927\n",
            "   loaders:2回目    loss:1.2990429401397705\n",
            "   loaders:3回目    loss:2.267598867416382\n",
            "   loaders:4回目    loss:1.775049090385437\n",
            "   loaders:5回目    loss:1.5738646984100342\n",
            "   loaders:6回目    loss:1.5442981719970703\n",
            "   loaders:7回目    loss:1.3942601680755615\n",
            "EPOCH34回目 val Loss: 1.4205 Acc: 0.5500\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.001887918682768941\n",
            "   loaders:2回目    loss:0.0010187712032347918\n",
            "   loaders:3回目    loss:0.0016045990632846951\n",
            "   loaders:4回目    loss:0.0012118336744606495\n",
            "   loaders:5回目    loss:0.0010889617260545492\n",
            "   loaders:6回目    loss:0.0018240793142467737\n",
            "   loaders:7回目    loss:0.0008398017380386591\n",
            "   loaders:8回目    loss:0.0012871318031102419\n",
            "   loaders:9回目    loss:0.001328529673628509\n",
            "   loaders:10回目    loss:0.0011172202648594975\n",
            "   loaders:11回目    loss:0.0008670619572512805\n",
            "   loaders:12回目    loss:0.0025806089397519827\n",
            "   loaders:13回目    loss:0.0008871351019479334\n",
            "   loaders:14回目    loss:0.0011653895489871502\n",
            "   loaders:15回目    loss:0.0012615700252354145\n",
            "   loaders:16回目    loss:0.0009931850945577025\n",
            "   loaders:17回目    loss:0.0012880937429144979\n",
            "   loaders:18回目    loss:0.0009820825653150678\n",
            "   loaders:19回目    loss:0.002902152482420206\n",
            "   loaders:20回目    loss:0.0012975294375792146\n",
            "   loaders:21回目    loss:0.0010595782659947872\n",
            "   loaders:22回目    loss:0.004711465910077095\n",
            "   loaders:23回目    loss:0.0011746512027457356\n",
            "   loaders:24回目    loss:0.001032866071909666\n",
            "   loaders:25回目    loss:0.0025418223813176155\n",
            "   loaders:26回目    loss:0.001397809130139649\n",
            "   loaders:27回目    loss:0.0010292843217030168\n",
            "   loaders:28回目    loss:0.0011305782245472074\n",
            "   loaders:29回目    loss:0.0014312614221125841\n",
            "   loaders:30回目    loss:0.0009340698015876114\n",
            "   loaders:31回目    loss:0.0010167468572035432\n",
            "EPOCH35回目 train Loss: 0.0014 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.242799162864685\n",
            "   loaders:2回目    loss:1.2580177783966064\n",
            "   loaders:3回目    loss:2.2607369422912598\n",
            "   loaders:4回目    loss:1.7228331565856934\n",
            "   loaders:5回目    loss:1.6008301973342896\n",
            "   loaders:6回目    loss:1.5975542068481445\n",
            "   loaders:7回目    loss:1.450392246246338\n",
            "EPOCH35回目 val Loss: 1.4250 Acc: 0.5470\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0008306884556077421\n",
            "   loaders:2回目    loss:0.0008623288013041019\n",
            "   loaders:3回目    loss:0.0007425945368595421\n",
            "   loaders:4回目    loss:0.0009652478620409966\n",
            "   loaders:5回目    loss:0.000997988972812891\n",
            "   loaders:6回目    loss:0.0008724943618290126\n",
            "   loaders:7回目    loss:0.0012607366079464555\n",
            "   loaders:8回目    loss:0.0010333758546039462\n",
            "   loaders:9回目    loss:0.0010918396292254329\n",
            "   loaders:10回目    loss:0.0007109810248948634\n",
            "   loaders:11回目    loss:0.0008257656591013074\n",
            "   loaders:12回目    loss:0.001218549208715558\n",
            "   loaders:13回目    loss:0.0011194751132279634\n",
            "   loaders:14回目    loss:0.001141044427640736\n",
            "   loaders:15回目    loss:0.0009945110650733113\n",
            "   loaders:16回目    loss:0.000625711225438863\n",
            "   loaders:17回目    loss:0.0008321462664753199\n",
            "   loaders:18回目    loss:0.001483373693190515\n",
            "   loaders:19回目    loss:0.0014753106515854597\n",
            "   loaders:20回目    loss:0.0008514031651429832\n",
            "   loaders:21回目    loss:0.0011264531640335917\n",
            "   loaders:22回目    loss:0.0011565163731575012\n",
            "   loaders:23回目    loss:0.0009659893112257123\n",
            "   loaders:24回目    loss:0.0010892822174355388\n",
            "   loaders:25回目    loss:0.00101468653883785\n",
            "   loaders:26回目    loss:0.001786072039976716\n",
            "   loaders:27回目    loss:0.0013237301027402282\n",
            "   loaders:28回目    loss:0.0007547001005150378\n",
            "   loaders:29回目    loss:0.0012542216572910547\n",
            "   loaders:30回目    loss:0.0010926511604338884\n",
            "   loaders:31回目    loss:0.001185353845357895\n",
            "EPOCH36回目 train Loss: 0.0010 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.2817637920379639\n",
            "   loaders:2回目    loss:1.3279566764831543\n",
            "   loaders:3回目    loss:2.2309179306030273\n",
            "   loaders:4回目    loss:1.765443205833435\n",
            "   loaders:5回目    loss:1.5697962045669556\n",
            "   loaders:6回目    loss:1.5897111892700195\n",
            "   loaders:7回目    loss:1.4382445812225342\n",
            "EPOCH36回目 val Loss: 1.4341 Acc: 0.5380\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.001587937120348215\n",
            "   loaders:2回目    loss:0.0007448010728694499\n",
            "   loaders:3回目    loss:0.0012778857490047812\n",
            "   loaders:4回目    loss:0.001091739279218018\n",
            "   loaders:5回目    loss:0.0011454863706603646\n",
            "   loaders:6回目    loss:0.0012955950805917382\n",
            "   loaders:7回目    loss:0.0016443126369267702\n",
            "   loaders:8回目    loss:0.0010790567612275481\n",
            "   loaders:9回目    loss:0.0009911120869219303\n",
            "   loaders:10回目    loss:0.0012099393643438816\n",
            "   loaders:11回目    loss:0.0009147445089183748\n",
            "   loaders:12回目    loss:0.0011460669338703156\n",
            "   loaders:13回目    loss:0.0007944349199533463\n",
            "   loaders:14回目    loss:0.0010132669704034925\n",
            "   loaders:15回目    loss:0.0015540756285190582\n",
            "   loaders:16回目    loss:0.0007550482405349612\n",
            "   loaders:17回目    loss:0.0010217266390100121\n",
            "   loaders:18回目    loss:0.0015213331207633018\n",
            "   loaders:19回目    loss:0.0015175020089372993\n",
            "   loaders:20回目    loss:0.0007376213907264173\n",
            "   loaders:21回目    loss:0.0007303493330255151\n",
            "   loaders:22回目    loss:0.0008164451573975384\n",
            "   loaders:23回目    loss:0.0012228598352521658\n",
            "   loaders:24回目    loss:0.0012010025093331933\n",
            "   loaders:25回目    loss:0.0007937921327538788\n",
            "   loaders:26回目    loss:0.0011411128798499703\n",
            "   loaders:27回目    loss:0.001644532079808414\n",
            "   loaders:28回目    loss:0.0008266191580332816\n",
            "   loaders:29回目    loss:0.0008070356561802328\n",
            "   loaders:30回目    loss:0.0008521286072209477\n",
            "   loaders:31回目    loss:0.0011945645092055202\n",
            "EPOCH37回目 train Loss: 0.0011 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.2764897346496582\n",
            "   loaders:2回目    loss:1.278507947921753\n",
            "   loaders:3回目    loss:2.2679219245910645\n",
            "   loaders:4回目    loss:1.7339403629302979\n",
            "   loaders:5回目    loss:1.610756754875183\n",
            "   loaders:6回目    loss:1.5463838577270508\n",
            "   loaders:7回目    loss:1.36319100856781\n",
            "EPOCH37回目 val Loss: 1.4179 Acc: 0.5540\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0008310277480632067\n",
            "   loaders:2回目    loss:0.0012225148966535926\n",
            "   loaders:3回目    loss:0.0006053872057236731\n",
            "   loaders:4回目    loss:0.000935251300688833\n",
            "   loaders:5回目    loss:0.0010663741268217564\n",
            "   loaders:6回目    loss:0.0011352143483236432\n",
            "   loaders:7回目    loss:0.0011576688848435879\n",
            "   loaders:8回目    loss:0.0007874825387261808\n",
            "   loaders:9回目    loss:0.0010744434548541903\n",
            "   loaders:10回目    loss:0.001155972946435213\n",
            "   loaders:11回目    loss:0.0008612250676378608\n",
            "   loaders:12回目    loss:0.001398557098582387\n",
            "   loaders:13回目    loss:0.001073696301318705\n",
            "   loaders:14回目    loss:0.0014461139217019081\n",
            "   loaders:15回目    loss:0.000878360471688211\n",
            "   loaders:16回目    loss:0.0010409218957647681\n",
            "   loaders:17回目    loss:0.0010760386940091848\n",
            "   loaders:18回目    loss:0.0007056124741211534\n",
            "   loaders:19回目    loss:0.0008411100716330111\n",
            "   loaders:20回目    loss:0.0010388465598225594\n",
            "   loaders:21回目    loss:0.0009504506015218794\n",
            "   loaders:22回目    loss:0.0008116005919873714\n",
            "   loaders:23回目    loss:0.0009881583973765373\n",
            "   loaders:24回目    loss:0.0006704270490445197\n",
            "   loaders:25回目    loss:0.0011634151451289654\n",
            "   loaders:26回目    loss:0.0007629696046933532\n",
            "   loaders:27回目    loss:0.0014464950654655695\n",
            "   loaders:28回目    loss:0.0009497248101979494\n",
            "   loaders:29回目    loss:0.0009586469386704266\n",
            "   loaders:30回目    loss:0.0006921880994923413\n",
            "   loaders:31回目    loss:0.001684745424427092\n",
            "EPOCH38回目 train Loss: 0.0010 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.3478800058364868\n",
            "   loaders:2回目    loss:1.3053348064422607\n",
            "   loaders:3回目    loss:2.185819149017334\n",
            "   loaders:4回目    loss:1.7640166282653809\n",
            "   loaders:5回目    loss:1.5405659675598145\n",
            "   loaders:6回目    loss:1.5991158485412598\n",
            "   loaders:7回目    loss:1.3882462978363037\n",
            "EPOCH38回目 val Loss: 1.4248 Acc: 0.5500\n",
            "train:フェイズ\n",
            "   loaders:1回目    loss:0.0007294550887309015\n",
            "   loaders:2回目    loss:0.0011598172131925821\n",
            "   loaders:3回目    loss:0.0012422619620338082\n",
            "   loaders:4回目    loss:0.001112253637984395\n",
            "   loaders:5回目    loss:0.0006204769597388804\n",
            "   loaders:6回目    loss:0.0006628683186136186\n",
            "   loaders:7回目    loss:0.0008756970055401325\n",
            "   loaders:8回目    loss:0.0012821858981624246\n",
            "   loaders:9回目    loss:0.000871010881382972\n",
            "   loaders:10回目    loss:0.0009127545054070652\n",
            "   loaders:11回目    loss:0.0011102091521024704\n",
            "   loaders:12回目    loss:0.0007879259646870196\n",
            "   loaders:13回目    loss:0.0007586297579109669\n",
            "   loaders:14回目    loss:0.0006693424074910581\n",
            "   loaders:15回目    loss:0.0006732239853590727\n",
            "   loaders:16回目    loss:0.0006769489264115691\n",
            "   loaders:17回目    loss:0.0010943170636892319\n",
            "   loaders:18回目    loss:0.0007121032103896141\n",
            "   loaders:19回目    loss:0.0010318446438759565\n",
            "   loaders:20回目    loss:0.0009287895518355072\n",
            "   loaders:21回目    loss:0.0007738130516372621\n",
            "   loaders:22回目    loss:0.0007044253288768232\n",
            "   loaders:23回目    loss:0.0009420478600077331\n",
            "   loaders:24回目    loss:0.0008238276350311935\n",
            "   loaders:25回目    loss:0.0009762555127963424\n",
            "   loaders:26回目    loss:0.0010182142723351717\n",
            "   loaders:27回目    loss:0.0010096440091729164\n",
            "   loaders:28回目    loss:0.0008629725780338049\n",
            "   loaders:29回目    loss:0.0008450104505755007\n",
            "   loaders:30回目    loss:0.0011391476728022099\n",
            "   loaders:31回目    loss:0.0013575796037912369\n",
            "EPOCH39回目 train Loss: 0.0009 Acc: 0.9920\n",
            "val:フェイズ\n",
            "   loaders:1回目    loss:1.251820683479309\n",
            "   loaders:2回目    loss:1.298172116279602\n",
            "   loaders:3回目    loss:2.209782361984253\n",
            "   loaders:4回目    loss:1.7945022583007812\n",
            "   loaders:5回目    loss:1.5877636671066284\n",
            "   loaders:6回目    loss:1.5374696254730225\n",
            "   loaders:7回目    loss:1.3986878395080566\n",
            "EPOCH39回目 val Loss: 1.4180 Acc: 0.5470\n",
            "Best val Acc: 0.558000\n",
            "[0.22025 0.329   0.39475 0.44725 0.497   0.5455  0.59625 0.637   0.66\n",
            " 0.692   0.72125 0.77225 0.80175 0.83775 0.8635  0.886   0.92    0.916\n",
            " 0.93325 0.954   0.96925 0.981   0.987   0.98875 0.9875  0.98975 0.99075\n",
            " 0.99125 0.992   0.992   0.992   0.992   0.992   0.992   0.992   0.992\n",
            " 0.992   0.992   0.992   0.992  ]\n",
            "[0.197 0.317 0.358 0.309 0.328 0.343 0.382 0.429 0.453 0.466 0.417 0.379\n",
            " 0.481 0.43  0.391 0.465 0.434 0.427 0.419 0.467 0.509 0.505 0.525 0.529\n",
            " 0.513 0.541 0.524 0.535 0.551 0.548 0.552 0.549 0.558 0.547 0.55  0.547\n",
            " 0.538 0.554 0.55  0.547]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#学習したモデルを使ってtestデータの推論を実施\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import albumentations\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "work_dir           = '/content/sample_data'\n",
        "save_dir           = '/content/drive/MyDrive/2024_AIContest2/Thema1/'\n",
        "test_zip_file_path = '/content/sample_data/test_images.zip'\n",
        "test_file_dir      = os.path.join(work_dir, 'test_images')\n",
        "report_format_tsv  = os.path.join(work_dir, 'sample_submit.tsv')\n",
        "best_model_path    = os.path.join(save_dir, 'pth/20250317_original_model_14.pth')\n",
        "output_file        = os.path.join(save_dir, 'output/20250317_out_submit_14.tsv')\n",
        "\n",
        "TARGET_NUM = 10\n",
        "\n",
        "# ZIPファイルを解凍する\n",
        "def extract_zip(zip_file_path, extract_to):\n",
        "\n",
        "    if not os.path.exists(test_file_dir):\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "\n",
        "extract_zip(test_zip_file_path, work_dir)\n",
        "\n",
        "#dataサイズ定義\n",
        "dataset_sizes= {\n",
        "    'train':len(image_datasets['train']),\n",
        "    'val':len(image_datasets['val'])\n",
        "}\n",
        "\n",
        "#submit用dataset定義\n",
        "class For_Submission_Datasets(Dataset):\n",
        "\n",
        "    def __init__(self, data_transform):\n",
        "        self.df = pd.read_csv(report_format_tsv ,sep='\\t',names=['filename','target'])\n",
        "        self.data_transform = data_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file = self.df['filename'][index]\n",
        "        image = Image.open(test_file_dir +'/'+ file)\n",
        "        image = self.data_transform(image)\n",
        "\n",
        "        return image,file\n",
        "\n",
        "#submit用dataset作成\n",
        "subdataset = For_Submission_Datasets(data_transform=data_transforms['val'])\n",
        "\n",
        "#submit用dataloaders作成\n",
        "subdataloader = torch.utils.data.DataLoader(subdataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
        "\n",
        "#精度の最も高いモデルをロード\n",
        "#モデルの名前を適宜変更して、最も精度の高いモデルをロードしましょう\n",
        "best_model = get_model(target_num = TARGET_NUM)\n",
        "best_model.load_state_dict(torch.load(best_model_path, map_location=lambda storage, loc: storage), strict=True)\n",
        "\n",
        "submit = pd.read_csv(report_format_tsv,sep='\\t', header=None)\n",
        "#print(submit)\n",
        "#テストデータに対しての推論\n",
        "pred = []\n",
        "for i,(inputs, labels) in enumerate(subdataloader):\n",
        "    inputs = inputs.to(DEVICE)\n",
        "    best_model.eval()\n",
        "    outputs = best_model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    pred.append(preds.item())\n",
        "\n",
        "df_test = pd.read_csv(report_format_tsv ,sep='\\t',names=['filename','target'])\n",
        "\n",
        "df_test['pred'] = pred\n",
        "#print(df_test)\n",
        "submit[1] = pred\n",
        "\n",
        "submit.to_csv(output_file ,sep='\\t', index=False, header=False)\n",
        "print(submit)\n"
      ],
      "metadata": {
        "id": "qR88TigKZrpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985053bb-dd84-4ca4-e53b-ceee2e53d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  0  1\n",
            "0        test_0.jpg  6\n",
            "1        test_1.jpg  5\n",
            "2        test_2.jpg  0\n",
            "3        test_3.jpg  8\n",
            "4        test_4.jpg  7\n",
            "...             ... ..\n",
            "7995  test_7995.jpg  2\n",
            "7996  test_7996.jpg  6\n",
            "7997  test_7997.jpg  8\n",
            "7998  test_7998.jpg  8\n",
            "7999  test_7999.jpg  8\n",
            "\n",
            "[8000 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}